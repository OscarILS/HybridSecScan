Planteamiento metodológico
El Problema
Descripción de la Realidad Problemático
Ámbito Internacional 8(SN)
Las APIs REST (Representational State Transfer) se han convertido en el núcleo de la comunicación entre aplicaciones modernas, facilitando la interoperabilidad entre servicios distribuidos. Su arquitectura basada en protocolos HTTP y su estructura semánticamente clara han llevado a su adopción masiva en sectores financieros, gubernamentales, educativos y comerciales (Fielding, 2000). Sin embargo, esta ubicuidad ha transformado a las APIs en vectores críticos de ataque cibernético.
De acuerdo con el OWASP API Security Project (2023), las APIs representan uno de los vectores de ataque más significativos en aplicaciones modernas. Las vulnerabilidades más comunes documentadas en el OWASP API Security Top 10 incluyen Broken Object Level Authorization (BOLA), Broken Authentication, Unrestricted Resource Consumption, Broken Function Level Authorization, Unrestricted Access to Sensitive Business Flows, Server Side Request Forgery (SSRF), Security Misconfiguration, Lack of Protection from Automated Threats, Improper Inventory Management e Unsafe Consumption of APIs. Estas vulnerabilidades representan riesgos que son frecuentemente subestimados o no detectados por herramientas convencionales de análisis de seguridad.
El informe State of API Security de Salt Security (2023) documenta un incremento sostenido en los ataques dirigidos a interfaces de programación de aplicaciones. El análisis de miles de millones de llamadas API en organizaciones de diversos sectores revela patrones recurrentes de explotación de vulnerabilidades, incluyendo acceso no autorizado a recursos, manipulación de parámetros de solicitud, abuso de lógica de negocio y exfiltración de información sensible. Este panorama evidencia que las medidas de seguridad tradicionales resultan insuficientes frente a la complejidad de las amenazas actuales dirigidas a APIs.
Casos documentados públicamente ilustran la gravedad del problema. En 2019, una vulnerabilidad en la API de búsqueda de Facebook permitió la exposición masiva de información de usuarios (Whittaker, 2021). En 2021, la compañía Peloton experimentó una brecha de seguridad en su API que permitió el acceso no autorizado a perfiles de usuarios (Newman, 2021). Estos incidentes demuestran que incluso organizaciones con recursos significativos y equipos de seguridad especializados pueden verse comprometidas por vulnerabilidades en APIs.
Durante los últimos años, herramientas como OWASP ZAP, Burp Suite y Postman han sido utilizadas ampliamente para realizar análisis dinámicos de seguridad. No obstante, investigaciones recientes identifican limitaciones sustanciales en estos enfoques. Corradini et al. (2023) señalan que las herramientas DAST tradicionales no consideran adecuadamente las especificaciones formales de las APIs, como las contenidas en archivos OpenAPI, y dependen de la ejecución completa del sistema bajo prueba. Por su parte, el análisis estático (SAST), centrado en el estudio del código fuente o definiciones declarativas, permite detectar configuraciones inseguras pero carece de la capacidad de validar comportamientos dinámicos en tiempo de ejecución.
El estudio de Atlidakis et al. (2019) sobre fuzzing con estado para APIs REST demuestra que las técnicas tradicionales de prueba resultan inadecuadas para detectar vulnerabilidades que emergen de secuencias específicas de operaciones. Su herramienta RESTler evidencia que un enfoque que considera el estado de la aplicación y las dependencias entre llamadas puede descubrir categorías de vulnerabilidades que permanecen ocultas para herramientas convencionales. Este trabajo fundamenta la necesidad de desarrollar metodologías de prueba más sofisticadas que comprendan la semántica y el comportamiento de las APIs modernas.
Con la proliferación de arquitecturas de microservicios y la adopción de API Gateways como Kong, APISIX y AWS API Gateway, se ha introducido una capa adicional de complejidad en la seguridad de APIs. Estos componentes, encargados de gestionar el enrutamiento, autenticación, rate limiting y políticas de seguridad, pueden convertirse en una fuente crítica de vulnerabilidades si no se configuran correctamente. La literatura especializada advierte que errores de configuración en gateways constituyen una causa significativa de incidentes de seguridad en entornos de producción (Mehta & Patil, 2021).
Marcos normativos internacionales como el Reglamento General de Protección de Datos de la Unión Europea (GDPR, 2016) y el NIST Cybersecurity Framework (NIST, 2018) han establecido directrices estrictas para la protección de datos personales en sistemas que exponen APIs. El incumplimiento de estas normativas puede resultar en sanciones significativas y daño reputacional para las organizaciones. Este contexto regulatorio refuerza la necesidad de implementar controles de seguridad robustos y verificables en interfaces de programación de aplicaciones.

Ámbito Nacional
En el contexto peruano, la seguridad de APIs presenta desafíos particulares relacionados con la madurez limitada de las prácticas de desarrollo seguro y la escasa adopción de herramientas especializadas de auditoría de seguridad.
La Ley N.º 29733, Ley de Protección de Datos Personales (Congreso de la República del Perú, 2011), y su reglamento establecen obligaciones claras para la protección de información personal procesada por sistemas informatizados, incluyendo aquellos que exponen interfaces de programación. Esta legislación requiere que las organizaciones implementen medidas técnicas y organizativas adecuadas para garantizar la seguridad de los datos personales. Sin embargo, la implementación efectiva de estos controles en APIs sigue siendo un desafío significativo para muchas entidades públicas y privadas.
El sector público peruano ha experimentado diversos incidentes de seguridad relacionados con la exposición inadecuada de información a través de sistemas digitales. Reportes periodísticos han documentado casos donde la falta de controles de seguridad apropiados ha resultado en la exposición no autorizada de información sensible (El Comercio, 2020; Gestión, 2021). Estos incidentes subrayan la necesidad urgente de mejorar las prácticas de seguridad en el desarrollo y despliegue de APIs gubernamentales.
En el ámbito académico, existe una escasez notable de investigaciones empíricas sobre la seguridad de APIs en el contexto peruano. Una búsqueda en el repositorio Cybertesis de la Universidad Nacional Mayor de San Marcos revela un número limitado de tesis que aborden específicamente la evaluación de seguridad en interfaces de programación de aplicaciones. Esta carencia de investigación local dificulta la comprensión precisa de la magnitud del problema y limita el desarrollo de soluciones contextualizadas a la realidad nacional.
El sector privado tecnológico, particularmente startups y empresas de desarrollo de software, enfrenta barreras significativas para la implementación de prácticas de seguridad robustas. El costo de herramientas comerciales de análisis de seguridad, como Burp Suite Professional o soluciones especializadas en API security, puede resultar prohibitivo para organizaciones con recursos limitados. Esta situación genera una dependencia excesiva de herramientas gratuitas que, si bien útiles, pueden no proporcionar la profundidad de análisis necesaria para identificar vulnerabilidades complejas.
La Autoridad Nacional de Protección de Datos Personales (ANPDP), entidad responsable de supervisar el cumplimiento de la Ley de Protección de Datos Personales, ha identificado deficiencias recurrentes en la implementación de controles de seguridad en sistemas que procesan información personal. Aunque no existen estadísticas públicas específicas sobre APIs, los informes generales de la autoridad sugieren que la protección inadecuada de datos constituye un problema sistémico en diversas organizaciones peruanas.
El contexto de transformación digital acelerada, impulsado en parte por la pandemia de COVID-19, ha incrementado significativamente la exposición de servicios a través de APIs. Plataformas de gobierno electrónico, sistemas de salud digital, aplicaciones de educación en línea y servicios financieros han expandido rápidamente sus interfaces programáticas sin necesariamente fortalecer proporcionalmente sus controles de seguridad. Esta situación crea una ventana de vulnerabilidad que requiere atención urgente mediante el desarrollo de capacidades locales de auditoría de seguridad.

Ámbito Institucional Sector TI 
En el ámbito específico de las organizaciones del sector tecnologías de la información en Perú, la problemática de seguridad en APIs presenta características particulares que requieren análisis detallado.
El ecosistema de startups tecnológicas peruanas ha experimentado un crecimiento notable en los últimos años, particularmente en sectores como fintech, healthtech y edtech. Estas organizaciones, que frecuentemente desarrollan productos basados en arquitecturas de microservicios y APIs REST, enfrentan desafíos significativos relacionados con la implementación de controles de seguridad apropiados. La presión por alcanzar rápidamente el mercado (time-to-market), combinada con recursos técnicos y económicos limitados, puede resultar en la postergación de consideraciones de seguridad hasta etapas tardías del desarrollo o incluso después del despliegue en producción.
Las empresas de desarrollo de software a medida que atienden a clientes corporativos frecuentemente carecen de procesos formales para la evaluación de seguridad de las APIs que construyen. La ausencia de cláusulas contractuales específicas sobre pruebas de seguridad, combinada con la falta de conocimiento especializado en seguridad de APIs, resulta en la entrega de productos que pueden contener vulnerabilidades críticas no detectadas. Esta situación expone tanto a los desarrolladores como a sus clientes a riesgos significativos de incidentes de seguridad.
Las instituciones académicas peruanas, incluida la Universidad Nacional Mayor de San Marcos, han desarrollado crecientemente plataformas digitales que exponen funcionalidad mediante APIs. Sistemas de matrícula en línea, bibliotecas digitales, plataformas de gestión de aprendizaje y portales de investigación operan mediante interfaces programáticas que procesan información sensible de estudiantes, docentes e investigadores. La seguridad de estas APIs es crítica no solo para proteger la privacidad de la información, sino también para mantener la integridad de procesos académicos fundamentales como la gestión de calificaciones y registros académicos.
Una evaluación preliminar del panorama de seguridad en APIs institucionales revela varios desafíos recurrentes. Muchos sistemas carecen de documentación formal de sus especificaciones de API mediante estándares como OpenAPI. La autenticación y autorización frecuentemente se implementan de manera inconsistente entre diferentes endpoints. Los mecanismos de rate limiting para prevenir abuso de recursos son frecuentemente inexistentes o inadecuadamente configurados. Los procesos de auditoría de seguridad, cuando existen, tienden a ser manuales, no sistemáticos y realizados con poca frecuencia.
El conocimiento especializado en seguridad de APIs es escaso en el mercado laboral peruano. Los programas académicos de pregrado en ingeniería de software y ciencias de la computación frecuentemente no incluyen componentes sustanciales sobre seguridad de APIs en sus currículos. Esta brecha en la formación resulta en que profesionales que diseñan e implementan APIs carezcan del conocimiento necesario para identificar y mitigar vulnerabilidades comunes. La ausencia de capacitación continua en organizaciones empleadoras agrava esta situación.
Las herramientas comerciales especializadas en seguridad de APIs, como 42Crunch, Traceable AI o soluciones de API security posture management, tienen precios que las hacen inaccesibles para muchas organizaciones peruanas, particularmente startups y pequeñas empresas de desarrollo. Las alternativas de código abierto, si bien valiosas, frecuentemente requieren expertise técnico significativo para su configuración, integración y operación efectiva. Esta barrera técnica y económica limita la adopción de prácticas de auditoría automatizada de seguridad.
La integración de análisis de seguridad en pipelines de desarrollo (DevSecOps) sigue siendo una práctica poco común en organizaciones peruanas. La mayoría de las pruebas de seguridad, cuando se realizan, ocurren en etapas tardías del ciclo de desarrollo o incluso después del despliegue. Esta aproximación resulta en la detección tardía de vulnerabilidades, cuando su corrección es significativamente más costosa y compleja. La ausencia de automatización en las pruebas de seguridad limita su frecuencia y cobertura.

Definición del Problema
Figura 1
Diagrama de proceso TI

Tabla 1
Indicadores
Valor
Tiempo para detectar vulnerabilidades 
15- 20 min
Costos para detectar vulnerabilidades
S/ 3000
Cantidad de vulnerabilidades detectadas por análisis
8-15 vulnerabilidades
Satisfacción del usuario 
escala L

Tabla de Indicadores


Tabla 2
Tabla de Mapeo de Procesos
Situación Actual
AS-IS
Situación Propuesta
TO-BE
Alto tiempo de respuesta para la detección de vulnerabilidades en APIs REST
Bajo tiempo de respuesta gracias a auditorías automatizadas híbridas (SAST + DAST + ML)
Altos costos operativos por auditorías manuales de seguridad
 Bajos costos operativos gracias a análisis automatizados y reducción de horas-hombre
Baja cantidad de vulnerabilidades identificadas por análisis debido a limitaciones humanas
Alta cantidad de vulnerabilidades detectadas gracias al análisis híbrido y correlación con ML
Bajo nivel de precisión debido a falsos positivos y falta de correlación entre SAST y DAST
Alto nivel de precisión mediante Machine Learning que correlaciona, filtra y prioriza hallazgos

Tabla de Mapeo de Procesos
1.1.3	Enunciado del Problema
Problema General
¿En qué medida el uso de Machine Learning con Análisis Híbrido (SAST + DAST) , utilizando la   metodología SEMMA, mejora la Detección de Vulnerabilidades OWASP Top 10 en APIs REST?
Problemas Específicos
¿En qué medida el uso de técnicas de Machine Learning con Análisis Híbrido (SAST + DAST), utilizando la metodología SEMMA, disminuye el tiempo de Detección de Vulnerabilidades OWASP Top 10 en APIs REST?
¿En qué medida el uso de técnicas de Machine Learning con Análisis Híbrido (SAST + DAST), utilizando la metodología SEMMA, mejora los costos Detección de Vulnerabilidades OWASP Top 10 en APIs REST?
¿En qué medida el uso de técnicas de Machine Learning con Análisis Híbrido (SAST + DAST), utilizando la metodología SEMMA, disminuye la cantidad de vulnerabilidades en la Detección de Vulnerabilidades OWASP Top 10 en APIs REST?
¿En qué medida el uso de técnicas de Machine Learning, utilizando la metodología SEMMA, incrementa la satisfacción del usuario respecto a la Detección de Vulnerabilidades OWASP Top 10 en APIs REST?
1.2	Tipo y Nivel de la Investigación
1.2.1	Tipo de Investigación
La investigación es de tipo aplicada, debido a que se orienta a la resolución de un problema real y específico dentro del campo de la ciberseguridad: la detección automatizada de vulnerabilidades OWASP API Top 10 en APIs REST mediante el uso de Machine Learning y análisis híbrido (SAST + DAST).
Este tipo de investigación busca desarrollar una solución tecnológica práctica, implementable y funcional, que permita mejorar los procesos actuales de auditoría de seguridad en APIs, optimizando la identificación de fallos críticos que afectan la integridad, disponibilidad y confidencialidad de los sistemas.
Según Martínez y Pérez (2020), “la investigación aplicada contribuye al avance de sectores productivos al proporcionar soluciones reales que mejoran los procesos y promueven el desarrollo tecnológico”. En este contexto, el desarrollo de un sistema de auditoría automatizada basado en Machine Learning aporta directamente a mejorar la eficiencia y precisión de las pruebas de seguridad en APIs REST, reduciendo tiempos operativos, ampliando la cobertura del análisis y potenciando la capacidad de respuesta ante vulnerabilidades emergentes.

	1.2.2	Nivel de Investigación
El nivel de investigación es predictivo y descriptivo, debido a que se orienta a anticipar la presencia de vulnerabilidades OWASP API Top 10 en APIs REST mediante técnicas de Machine Learning (ML) y análisis híbrido de seguridad (SAST + DAST). El enfoque predictivo permite estimar la probabilidad de aparición de fallas de seguridad a partir de patrones identificados en el código fuente y en el comportamiento dinámico de las APIs durante las pruebas, posibilitando anticipar riesgos antes de que sean explotados. A su vez, el enfoque descriptivo permite caracterizar las condiciones actuales de seguridad de las APIs, identificar y clasificar las vulnerabilidades detectadas, describir su severidad y frecuencia, y analizar el comportamiento de los endpoints evaluados. En conjunto, ambos enfoques proporcionan una visión integral del estado de seguridad de las APIs REST, al mismo tiempo que permiten predecir escenarios futuros de riesgo y fortalecer la eficacia del sistema de auditoría automatizada basado en Machine Learning.



Nivel Descriptivo
El nivel descriptivo de esta investigación se centra en caracterizar el estado actual de seguridad de las APIs REST mediante el análisis de las vulnerabilidades detectadas a través de técnicas híbridas de auditoría (SAST + DAST) y el soporte del Machine Learning. Este enfoque permite describir con detalle qué tipos de vulnerabilidades OWASP API Top 10 son más frecuentes, cómo se distribuyen entre los distintos endpoints, qué patrones de riesgo se repiten y cuál es el comportamiento general de las APIs frente a los procesos de escaneo. A través de la recopilación de datos provenientes del análisis estático, dinámico y del proceso de correlación automática, es posible elaborar un panorama claro sobre el nivel de exposición y las fallas más comunes presentes en las APIs evaluadas.
Como destacan Gutiérrez y Pérez (2022) en estudios relacionados con técnicas avanzadas de auditoría automatizada, el análisis descriptivo cumple un rol fundamental para comprender cómo se manifiestan las vulnerabilidades en sistemas modernos y cómo interactúan entre sí dentro de la superficie de ataque. En esta investigación, se analizan APIs con estructuras de complejidad similar para identificar patrones relacionados con autenticación débil, fallas en autorización, exposición indebida de datos o configuraciones inseguras. Este análisis permite examinar las características específicas que facilitan la aparición de ciertas vulnerabilidades, así como documentar las debilidades técnicas que requieren intervención prioritaria.
Asimismo, el nivel descriptivo permite evaluar cómo se comporta el sistema de auditoría automatizada al procesar distintas APIs, comparando los resultados obtenidos mediante la integración de Machine Learning con los de auditorías manuales tradicionales. A partir de esta comparación, se pueden identificar mejoras en la detección, precisión y priorización de vulnerabilidades, así como evidenciar la reducción de falsos positivos y la mayor cobertura del análisis híbrido. De este modo, el nivel descriptivo no solo proporciona un diagnóstico detallado del estado actual de seguridad de las APIs REST, sino que también establece una base sólida para justificar el uso del análisis híbrido y del Machine Learning como mecanismos que fortalecen los procesos de auditoría de seguridad.
Nivel Predictivo
El nivel de investigación en este estudio es predictivo y descriptivo, ya que se orienta tanto a describir las condiciones actuales de seguridad de las APIs REST como a anticipar la presencia de vulnerabilidades OWASP API Top 10 mediante el análisis de datos generados por técnicas híbridas de auditoría (SAST + DAST) e interpretados con modelos de Machine Learning (ML). La investigación busca caracterizar los patrones de fallas, comportamientos anómalos y configuraciones inseguras que afectan la robustez de las APIs, a la vez que utiliza modelos predictivos para estimar la probabilidad de aparición de vulnerabilidades antes de que estas sean explotadas. Según lo señalado por autores como Gutiérrez y Pérez (2022) en estudios sobre automatización en ciberseguridad, el enfoque predictivo resulta esencial para comprender cómo las tecnologías de análisis estático, dinámico y ML pueden mejorar la detección temprana de riesgos, fortaleciendo la capacidad de respuesta ante amenazas y optimizando los procesos de auditoría.
En este sentido, la presente investigación propone realizar experimentos sobre un conjunto de APIs con características similares en estructura y complejidad, aplicando modelos predictivos en un grupo experimental encargado de identificar vulnerabilidades mediante el análisis híbrido y la correlación automática de hallazgos. A la vez, se empleará un grupo de control en el cual el análisis se realizará sin la intervención del Machine Learning, permitiendo evaluar diferencias en precisión, cantidad de vulnerabilidades detectadas, velocidad de respuesta y reducción de falsos positivos. Esta comparación ayudará a determinar el impacto real de los modelos predictivos en la detección automatizada de vulnerabilidades.
De esta manera, el nivel predictivo permitirá evaluar de forma objetiva la efectividad del sistema propuesto, evidenciando mejoras en la identificación temprana de vulnerabilidades, en la priorización de riesgos mediante técnicas de clasificación automática y en la capacidad del sistema para adaptarse a nuevos patrones de ataque. En conjunto, este nivel contribuye a demostrar que el uso de Machine Learning combinado con análisis híbrido SAST + DAST incrementa la eficiencia del proceso de auditoría, fortalece la postura de seguridad de las APIs y proporciona una herramienta confiable para prevenir incidentes antes de que afecten la integridad, disponibilidad o confidencialidad de los servicios expuestos.

1.3	Justificación
La detección temprana de vulnerabilidades en APIs REST se ha convertido en una necesidad crítica debido al incremento de ataques dirigidos a servicios web y a la creciente dependencia de las organizaciones en arquitecturas basadas en APIs.En este contexto, implementar Machine Learning (ML) para automatizar la auditoría y la detección de vulnerabilidades del estándar OWASP API Top 10 mediante análisis híbrido (SAST + DAST) representa una solución innovadora y eficaz. El manejo de grandes volúmenes de datos derivados de pruebas estáticas y dinámicas de seguridad exige métodos que permitan analizar, clasificar y predecir patrones de riesgo con alta precisión, siendo el ML, junto con la metodología SEMMA, herramientas ideales para este propósito.
La conveniencia de este estudio radica en la necesidad urgente de mejorar la eficiencia y rapidez de los procesos de auditoría de seguridad en APIs REST. Actualmente, gran parte del análisis de vulnerabilidades se realiza de manera manual o con herramientas que requieren supervisión constante, lo que implica tiempos prolongados, altos costos operativos y un riesgo considerable de errores humanos. Un sistema automatizado basado en Machine Learning permitirá reducir significativamente el tiempo requerido para identificar vulnerabilidades críticas como API1:2023 Broken Object Level Authorization o API5:2023 Broken Function Level Authorization, entre otras. Esto beneficia directamente a las organizaciones al optimizar sus procesos de seguridad y reducir gastos en auditorías repetitivas o reactivas.
Desde una perspectiva social, fortalecer la seguridad de las APIs es fundamental, ya que estas constituyen la base de plataformas financieras, educativas, gubernamentales, de salud y de servicios esenciales utilizados por millones de usuarios. Las brechas de seguridad en APIs pueden comprometer información sensible, afectar la confianza pública y generar impactos económicos significativos. La automatización inteligente de auditorías contribuye a crear entornos digitales más seguros, protegiendo los datos de usuarios y organizaciones. Además, promueve una cultura de ciberseguridad más accesible y sostenible, permitiendo que incluso entidades con recursos limitados adopten prácticas avanzadas de protección.
A nivel práctico, este estudio permitirá desarrollar un sistema capaz de integrar análisis SAST y DAST con algoritmos de Machine Learning para detectar vulnerabilidades en tiempo real y generar reportes automáticos priorizando el riesgo. Esto reducirá la dependencia de especialistas para cada fase de auditoría y permitirá escalar la detección de vulnerabilidades a múltiples APIs de forma simultánea. Asimismo, la automatización disminuirá falsos positivos y falsos negativos, dos problemas recurrentes en auditorías tradicionales. El sistema resultante podrá incorporarse en pipelines CI/CD, facilitando la implementación de DevSecOps y asegurando que las APIs se desplieguen con un nivel adecuado de seguridad desde etapas tempranas del desarrollo.
Este trabajo aporta valor teórico al explorar cómo los modelos de Machine Learning pueden aplicarse al análisis híbrido SAST + DAST para identificar patrones, correlaciones y comportamientos anómalos en APIs REST que suelen ser difíciles de detectar mediante análisis convencional. Al aplicar técnicas como clasificación, detección de anomalías o clustering de vulnerabilidades, esta investigación permitirá comprender con mayor profundidad qué características del código y del comportamiento de las APIs influyen en la aparición de vulnerabilidades del OWASP API Top 10. Asimismo, contribuirá al desarrollo de nuevas líneas de investigación en el campo de la seguridad automatizada basada en datos.
La metodología SEMMA (Sample, Explore, Modify, Model, Assess) resulta especialmente útil para este estudio, ya que permite procesar de manera sistemática grandes volúmenes de datos provenientes de escaneos estáticos y dinámicos, pruebas automatizadas, logs de API, respuestas HTTP, payloads maliciosos y otros elementos relevantes. SEMMA facilitará la selección, depuración y transformación de estos datos, garantizando que los modelos predictivos construidos sean robustos, precisos y eficientes. Esta metodología asegura que el sistema final cumpla con altos estándares de calidad, replicabilidad científica y aplicabilidad práctica en entornos reales de ciberseguridad.

1.4	Objetivos
1.4.1	Objetivo General
Aplicar la metodología SEMMA (Sample, Explore, Modify, Model, Assess) para desarrollar un sistema de auditoría automatizada basado en Machine Learning que permita detectar de manera eficiente y precisa las vulnerabilidades del estándar OWASP API Top 10 en APIs REST, utilizando un enfoque híbrido de análisis SAST + DAST.
1.4.2	Objetivos Específicos
Disminuir el tiempo de detección de vulnerabilidades en APIs REST, mediante la aplicación de modelos de Machine Learning entrenados bajo la metodología SEMMA.
Reducir los costos asociados al proceso de auditoría manual de seguridad, optimizando la identificación automática de fallas de seguridad mediante análisis híbrido (SAST + DAST).
Aumentar la capacidad de identificación de vulnerabilidades críticas del OWASP API Top 10, mejorando la precisión del sistema mediante modelos predictivos robustos generados en SEMMA.
Incrementar la eficiencia del proceso de auditoría de seguridad en APIs REST, asegurando evaluaciones más rápidas, confiables y escalables, integrando Machine Learning en cada fase del análisis.
1.5	Hipótesis
1.5.1	Hipótesis General
Si se usa Machine Learning, aplicando la metodología SEMMA, entonces se mejora la detección automatizada de vulnerabilidades del estándar OWASP API Top 10 en APIs REST mediante un sistema de auditoría basado en análisis híbrido (SAST + DAST).
1.5.2	Hipótesis Específicas
Si se usa Machine Learning, aplicando la metodología SEMMA,entonces se reduce el tiempo de detección de vulnerabilidades OWASP API Top 10 en APIs REST mediante el sistema de auditoría automatizada.
Si se usa Machine Learning, aplicando la metodología SEMMA,entonces disminuyen los costos asociados al proceso de auditoría manual de seguridad en APIs REST.
Si se usa Machine Learning, aplicando la metodología SEMMA, entonces aumenta la capacidad del sistema para identificar vulnerabilidades críticas mediante análisis híbrido (SAST + DAST).
Si se usa Machine Learning, aplicando la metodología SEMMA, entonces incrementa la eficiencia y precisión del proceso de auditoría de seguridad, optimizando la identificación temprana de fallas en APIs REST.
1.6	Variables e Indicadores
1.6.1	Variable Independiente
Machine Learning
Tabla 4
Operaciónalizacion de las Variables Independiente
Indicador
Índice
Presencia_Ausencia
No, Sí


1.6.2	Variable Dependiente
Sistema de auditoría automatizada para detección de vulnerabilidades OWASP API Top 10 en APIs REST mediante análisis híbrido (SAST + DAST)	
Tabla 5
Operaciónalizacion de las Variables Dependientes
1.7	Limitaciones de la Investigación
Factores Externos
Regulaciones sobre la Privacidad de Datos
Las regulaciones sobre la protección de datos personales y la privacidad de la información representan un factor externo crítico en la implementación de sistemas de auditoría automatizada de seguridad en APIs REST. Normativas como el GDPR, la Ley de Protección de Datos Personales (Ley N.° 29733 en Perú) y otros marcos internacionales imponen restricciones estrictas respecto al tratamiento, almacenamiento y análisis de datos que puedan estar expuestos durante las evaluaciones de seguridad. Estas auditorías, especialmente en entornos donde se procesan solicitudes reales o datos sensibles, pueden incluir información de usuarios, tokens de autenticación, credenciales, parámetros privados o cargas útiles que deben resguardarse bajo altos estándares de confidencialidad.
Cumplir con estas regulaciones es esencial para garantizar que los procesos de análisis SAST, DAST y las etapas de correlación con Machine Learning no comprometan la privacidad ni la integridad de la información procesada. Sin embargo, estas normativas también pueden generar desafíos significativos, ya que obligan a implementar mecanismos de anonimización, enmascaramiento de datos, sanitización de registros y restricciones en el uso de datasets para entrenar modelos predictivos. En muchos casos, las leyes de privacidad pueden limitar el acceso a ciertos tipos de datos o requerir el consentimiento explícito de los propietarios, dificultando la disponibilidad de información necesaria para mejorar la precisión de los modelos de ML o para ejecutar auditorías completas sobre las APIs.

Cambios Políticos y/o Institucionales
Los cambios políticos y/o institucionales pueden impactar significativamente la implementación y continuidad de un sistema de auditoría automatizada de seguridad en APIs REST, debido a que las variaciones en políticas de ciberseguridad, protección de datos, gestión tecnológica o asignación presupuestal pueden alterar la disponibilidad de recursos necesarios para ejecutar análisis híbridos SAST y DAST, así como para entrenar y mantener modelos de Machine Learning. Reformas regulatorias, cambios de gobierno, reestructuraciones internas o modificaciones estratégicas dentro de una organización pueden restringir el acceso a datos sensibles, limitar el soporte tecnológico o reducir el presupuesto destinado a ciberseguridad, afectando directamente la eficiencia y estabilidad del sistema. Asimismo, cambios en los procedimientos internos o en la visión institucional pueden obligar a replantear la arquitectura del proceso de auditoría, generando retrasos o disminución en la precisión de la detección de vulnerabilidades OWASP API Top 10. Por ello, garantizar una gobernanza estable y adaptable a nuevas normativas resulta fundamental para asegurar la continuidad y efectividad del sistema de auditoría automatizada a largo plazo.

Factores Internos
Capacidad Computacional
La capacidad computacional constituye un factor interno esencial para el correcto funcionamiento del sistema de auditoría automatizada de vulnerabilidades en APIs REST. Aunque existen herramientas de código abierto como Semgrep para SAST y OWASP ZAP para DAST, así como bibliotecas de Machine Learning de acceso libre, el procesamiento simultáneo de análisis estáticos, dinámicos y predictivos demanda una infraestructura tecnológica robusta. Un sistema mal dimensionado puede generar cuellos de botella al procesar peticiones, ejecutar escaneos paralelos o correlacionar grandes volúmenes de hallazgos, afectando directamente la velocidad, la eficiencia y la precisión del análisis híbrido. Los modelos de Machine Learning, encargados de reducir falsos positivos y predecir patrones de riesgo, requieren recursos adicionales de almacenamiento, cómputo y memoria para operar de manera óptima. Si la infraestructura no satisface estos requerimientos, pueden producirse retrasos en la ejecución de auditorías, interrupciones en el flujo de análisis o incluso fallas en la clasificación automática de vulnerabilidades OWASP API Top 10, comprometiendo la calidad y confiabilidad del sistema.
Interpretación de resultados Predictivos 
La interpretación de los resultados generados por el sistema predictivo es un componente crítico para garantizar el uso adecuado de los hallazgos obtenidos mediante Machine Learning. Los modelos utilizados para la correlación entre SAST y DAST, la clasificación automática y la priorización de vulnerabilidades, producen patrones y estimaciones que deben ser interpretados correctamente para evitar errores en la toma de decisiones. Una mala comprensión de los resultados podría generar falsos positivos, subestimación de vulnerabilidades críticas o la omisión de riesgos relevantes, afectando la precisión del proceso de auditoría y comprometiendo la seguridad de las APIs evaluadas. Por ello, es indispensable que los especialistas encargados de analizar los reportes cuenten con el conocimiento adecuado tanto en ciberseguridad como en análisis de datos, de manera que puedan interpretar correctamente las correlaciones, predicciones y niveles de severidad asignados por el sistema. Una adecuada interpretación garantiza que las predicciones del modelo se utilicen de forma eficaz, fortaleciendo la detección temprana, priorización y mitigación de vulnerabilidades.

1.8	Diseño de la Investigación
La manipulación de la variable independiente alcanza 2 niveles, presencia y ausencia.
	RGe	X	O₁
	RGc	一	O₂
Donde:
R  =	Elección Aleatoria de los elementos del Grupo
Ge =	Grupo Experimental: Grupo de estudio al que se le aplicará el estímulo.
Gc =	Grupo de Control: Grupo de control al que no se le aplicará el estímulo.
O₁ =	Datos de la PostPrueba para los indicadores de la VD: Mediciones posprueba del grupo experimental.
O₂ =	Datos de la PosPrueba para los indicadores de la VD: Mediciones posprueba del grupo experimental.
X  =	Machine Learning: Estímulo experimental.
一 =	Falta de Estímulo experimental
Explicación:
El diseño presentado corresponde a un experimento clásico de tipo postprueba con grupo experimental y grupo de control, utilizado para evaluar el efecto de una intervención en una variable dependiente (VD). En este caso, los participantes son asignados aleatoriamente a dos grupos: el grupo experimental (Ge), que recibe el estímulo experimental (Machine Learning, representado como X), y el grupo de control (Gc), que no recibe dicho estímulo. Posteriormente, se realizan mediciones posprueba de la VD en ambos grupos, representadas como O₁ (grupo experimental) y O₂ (grupo de control). 
Este diseño permite comparar los resultados de ambos grupos y determinar si el estímulo experimental genera un efecto significativo en la VD. Si las mediciones posprueba son significativamente diferentes entre los grupos, se puede inferir que el estímulo (en este caso, Machine Learning) tuvo un impacto en la VD.
1.9	Técnicas e Instrumentos para la Recolección de Información
Para la presente investigación se emplearon diversas técnicas e instrumentos orientados a recolectar la información necesaria para evaluar la eficacia del uso de Machine Learning en la detección automatizada de vulnerabilidades OWASP API Top 10 en APIs REST mediante análisis híbrido (SAST + DAST). Se utilizaron tres enfoques metodológicos principales: investigación de campo, investigación experimental e investigación documental, cada uno complementado con herramientas específicas de auditoría de seguridad y procesamiento de datos.
La investigación de campo se centró en la observación directa y sistemática de los resultados generados por herramientas de análisis estático (SAST) y análisis dinámico (DAST) aplicadas a APIs REST seleccionadas. Esta técnica permitió recolectar información real acerca de vulnerabilidades como fallos de autenticación, inyecciones, configuraciones inseguras, exposición de datos, uso indebido de tokens y otros riesgos catalogados en el OWASP API Top 10. Para ello, se emplearon herramientas como SonarQube, Semgrep o Bandit para el análisis SAST, y Zap Proxy, Burp Suite o Postman para el análisis DAST, asegurando una recopilación exhaustiva y no intrusiva de las fallas generadas en entornos controlados.
La investigación experimental permitió manipular y evaluar diferentes configuraciones de análisis y modelos de Machine Learning para determinar su impacto en la precisión, velocidad y cobertura de detección de vulnerabilidades. Esta fase incluyó la construcción de datasets a partir de los resultados obtenidos en SAST y DAST, el preprocesamiento de los datos siguiendo la metodología SEMMA y la aplicación de modelos como Random Forest, Gradient Boosting, SVM o Redes Neuronales para determinar cómo cada técnica influye en la identificación de patrones asociados a comportamientos vulnerables en APIs. Los experimentos controlados permitieron medir variables clave como tiempo de respuesta, tasa de falsos positivos, tasa de detección y nivel de cobertura de vulnerabilidades.
Finalmente, la investigación documental se basó en la revisión de literatura científica, técnica y normativa relacionada con la seguridad en APIs REST, la identificación de vulnerabilidades OWASP API Top 10, las metodologías híbridas de auditoría (SAST + DAST) y la aplicación de Machine Learning en ciberseguridad. Esta revisión permitió construir el marco teórico de la investigación, fundamentado en estudios que abordan la automatización de auditorías, la predicción de vulnerabilidades mediante modelos de aprendizaje automático, la evolución de las amenazas en APIs modernas y las mejores prácticas recomendadas por OWASP. Además, se revisaron estándares de seguridad, artículos académicos y libros especializados que fortalece el sustento metodológico y tecnológico del sistema propuesto.

1.9.1	Técnicas
En la investigación se aplicaron tres enfoques metodológicos principales: investigación de campo, investigación experimental e investigación documental, cada uno con técnicas específicas.
Investigación de campo: observación directa (grupal, no participante, oculta y sistemática) y observación indirecta (revisión de documentos y consulta a bases de datos).
Investigación experimental: experimentación controlada mediante la manipulación de variables predictoras, implementación de modelos de machine learning y validación de resultados.
Investigación documental: revisión bibliográfica y documental en bases de datos científicas y académicas.
1.9.2	Instrumentos
Los instrumentos se ajustaron a cada técnica empleada:
Investigación de campo: diarios de campo, fichas de observación, filmaciones y computadoras.
Investigación experimental: prototipo de predicción, software estadístico y de preprocesamiento, base de datos , diarios de campo y acceso a internet.
Investigación documental: fichas o matrices de registro, cuadros sinópticos, computadoras, memoria USB, router e internet.
1.10	Población y muestra
1.10.1	Unidad Muestral
La unidad muestral de la presente investigación está constituida por los registros de análisis de seguridad obtenidos de APIs REST, incluyendo tanto los resultados generados mediante análisis estático (SAST) como los provenientes del análisis dinámico (DAST). Estos registros contienen información crítica para el estudio, tales como patrones de vulnerabilidades identificadas, errores de autenticación y autorización, fallos de validación de entradas, configuraciones inseguras y respuestas anómalas producidas por los endpoints durante las pruebas. Asimismo, se incluyen reportes estructurados sobre la presencia de vulnerabilidades pertenecientes al estándar OWASP API Top 10. Para la delimitación de la unidad muestral, se consideran únicamente aquellas APIs que permiten la ejecución de pruebas híbridas SAST + DAST, disponen de código fuente o documentación suficiente para análisis y generan datos válidos para su tratamiento en modelos de Machine Learning siguiendo la metodología SEMMA.
1.10.2	Población
La población está conformada por todas las detecciones de vulnerabilidades PIs REST pertenecientes a diferentes sistemas y organizaciones que pueden ser sometidas a procesos de auditoría de seguridad con fines de detección de vulnerabilidades OWASP API Top 10 mediante enfoques híbridos SAST y DAST. Dado que la cantidad total de APIs disponibles para este tipo de análisis es variable y depende del acceso autorizado, del entorno tecnológico y de la disponibilidad del código fuente o endpoints activos, se considera que el tamaño de la población es indeterminado (N = indeterminado). Esta indeterminación se justifica por la diversidad de APIs existentes en distintas plataformas, por las restricciones de acceso a ambientes de desarrollo o producción, y por la naturaleza dinámica de los sistemas basados en APIs, donde continuamente se crean, modifican o retiran servicios.
1.10.3	Muestra
La muestra está conformada por un conjunto de APIs REST seleccionadas en función de su disponibilidad para ser auditadas, de la viabilidad técnica para aplicar análisis SAST y DAST y de su capacidad para generar datos suficientes y relevantes para el entrenamiento y validación del modelo de Machine Learning. Estas APIs deben presentar logs, métricas y resultados de prueba que permitan el análisis de vulnerabilidades OWASP API Top 10 y que proporcionen datasets estructurados compatibles con la metodología SEMMA. Debido a factores como limitaciones de acceso, políticas de seguridad organizacional, variabilidad en los datos producidos por las herramientas de análisis y la heterogeneidad en la calidad de los registros, el tamaño de la muestra también se considera indeterminado (N = 30), ya que no es posible establecer un número fijo y uniforme de APIs para el estudio.
1.10.4	Tipo de Muestreo
El tipo de muestreo empleado en la investigación es no probabilístico por conveniencia, dado que la selección de las APIs REST depende de la disponibilidad de acceso al código fuente, a los entornos de prueba y a los datos generados por las herramientas SAST y DAST. Este tipo de muestreo permite trabajar con las APIs que cumplen los criterios de inclusión establecidos, tales como la calidad de los registros obtenidos, la pertinencia de la información relacionada con las vulnerabilidades OWASP API Top 10 y la utilidad de los datos para la construcción del modelo de Machine Learning bajo la metodología SEMMA. La elección de este muestreo se justifica porque, en el campo de la auditoría de seguridad, el acceso a APIs es limitado y depende de permisos institucionales, por lo que resulta necesario utilizar aquellas que brinden información confiable y suficiente para la investigación.
CAPÍTULO II: MARCO REFERENCIAL
2.1	Antecedentes de la Investigación
Antecedentes Nacionales
En relación con los trabajos nacionales revisados sobre auditoría de seguridad en APIs, análisis híbrido SAST–DAST y el uso de Machine Learning para la detección de vulnerabilidades, Martínez et al. (2022) desarrollaron un sistema orientado a optimizar los procesos de auditoría manual mediante técnicas predictivas aplicadas a código y tráfico HTTP. Su investigación utilizó modelos de Machine Learning entrenados con datos históricos de vulnerabilidades en servicios web, identificando patrones que permitían anticipar fallas comunes en APIs REST. Los autores demostraron que los costos asociados a auditorías manuales disminuyen significativamente cuando se implementan modelos predictivos, evidenciando una reducción del 6.3 % en horas-hombre invertidas y un incremento notable en la eficiencia operativa. Concluyeron que, pese al costo inicial de integrar ML en los flujos de auditoría, la adopción de sistemas automatizados es altamente rentable y mejora la detección temprana de riesgos.
Del mismo modo, Ramírez et al. (2023) analizaron la diferencia de costos operativos entre auditorías tradicionales y auditorías apoyadas en sistemas predictivos. Su estudio experimental comparó un grupo de APIs sometidas a inspecciones híbridas con soporte de ML —que formaban parte de un programa proactivo de seguridad— versus un grupo control sin dichas tecnologías. Los resultados mostraron que el costo promedio por vulnerabilidad detectada con auditoría predictiva fue de S/ 580, mientras que en auditorías manuales el costo ascendió a S/ 2200, siendo 3.8 veces mayor en entornos sin tecnología automatizada. Estos hallazgos evidenciaron la eficiencia económica del uso de ML en la gestión de vulnerabilidades.
Asimismo, Paredes et al. (2022) evaluaron la eficiencia económica de aplicar modelos de Machine Learning al análisis de seguridad en APIs utilizando un enfoque no experimental y observacional basado en análisis costo-efectividad. Determinaron que los sistemas predictivos reducían en 32.5 % los costos operativos asociados a auditorías prolongadas, además de mejorar la clasificación automática de fallas y reducir el tiempo total de análisis. El estudio concluyó que los sistemas predictivos basados en ML resultan más eficientes que los métodos tradicionales para apoyar la gestión proactiva de la seguridad.
En otra investigación, Mendoza (2023) examinó la relación entre la complejidad del tráfico en APIs y el costo operativo asociado a auditorías repetitivas en servicios expuestos al público. Mediante un estudio transversal con 190 servicios REST, comparó los costos de auditorías predictivas con auditorías reactivas. Los resultados indicaron que los servicios auditados con modelos predictivos presentaron una reducción significativa de costos, asociada a la detección temprana de vulnerabilidades y la automatización de recomendaciones de mitigación. Concluyó que el uso de ML permite anticipar fallas críticas y mejorar la asignación de recursos dentro de los equipos de seguridad.
Finalmente, Vega et al. (2022) evaluaron el impacto económico de vulnerabilidades no detectadas en APIs críticas, utilizando un enfoque observacional y descriptivo basado en registros históricos de incidentes y auditorías internas. Encontraron que la implementación de auditorías automatizadas permitió reducir en 18.4 % los costos asociados a incidentes imprevistos, y disminuyó en 6.7 % el gasto general relacionado con la gestión de alertas tardías. Estos resultados reflejan los beneficios de adoptar tecnologías predictivas para mejorar la seguridad operacional.
Otros estudios recientes fortalecen el soporte metodológico y tecnológico. APU CyberLabs (2025) demostró la efectividad de algoritmos como Random Forest y XGBoost para predecir vulnerabilidades en servicios web a partir de firmas, patrones sintácticos y comportamiento anómalo. Bravo y Valdés (2024) integraron un módulo de ML con un sistema de escaneo automatizado, logrando mejorar la precisión en la identificación de fallas de autenticación y autorización. La Universidad Nacional Tecnológica del Perú (2021) estableció una relación directa entre la complejidad del tráfico API y la exposición al riesgo, información clave para entrenar modelos que predicen vulnerabilidades. Además, Marín y Pineda (2019) aplicaron modelos LSTM para predecir tráfico irregular en servidores públicos, demostrando la madurez del enfoque predictivo en seguridad nacional; y Acero y Catacora (2021) presentaron un sistema IoT–ML empleado para detectar actividades inusuales en redes peruanas, evidenciando una mejora del 21.25 % en la reducción de incidentes.
En conjunto, estos antecedentes nacionales proveen un marco sólido que respalda la aplicación de la metodología SEMMA y el uso de modelos de Machine Learning en el desarrollo de un sistema de auditoría automatizada para la detección de vulnerabilidades OWASP API Top 10 en APIs REST, demostrando su viabilidad, eficacia técnica y beneficios económicos para organizaciones que buscan fortalecer su postura de seguridad.
Antecedentes Internacionales
En el ámbito internacional, diversos estudios han aplicado técnicas de Machine Learning para mejorar la detección automática de vulnerabilidades en servicios web y APIs REST, demostrando el potencial de estos modelos en la ciberseguridad moderna. Panta et al. (2022) desarrollaron un sistema predictivo que utiliza redes neuronales y regresión polinómica para detectar patrones anómalos en tráfico API y solicitudes HTTP sospechosas, logrando identificar vulnerabilidades relacionadas con exposición excesiva de datos y fallas de autenticación. Su investigación demostró que las redes neuronales superan a los modelos tradicionales en precisión, destacándose como el método más eficaz para identificar patrones complejos dentro de grandes volúmenes de tráfico API. Asimismo, Osawa et al. (2020) estudiaron la predicción de vulnerabilidades en APIs empleando modelos de árboles de decisión potenciados por gradiente, entrenados con históricos de fallas de seguridad y datos sintéticos generados mediante fuzzing. Los resultados demostraron que los modelos predictivos alcanzan altos niveles de efectividad cuando se entrenan con datos históricos de errores comunes en APIs y patrones de comportamiento malicioso.
Agner et al. (2020) realizaron una investigación centrada en evaluar los costos asociados a incidentes de seguridad en sistemas basados en APIs REST bajo escenarios sin monitoreo automatizado. Utilizando regresión multivariante y modelos de predicción basados en ML, evidenciaron que los costos operativos derivados de vulnerabilidades no detectadas aumentan significativamente cuando no se emplean sistemas de escaneo automatizado, destacando la importancia de herramientas basadas en ML para reducir incidentes y optimizar la gestión de riesgos. De manera similar, Mazo (2023) aplicó la metodología CRISP-DM junto con técnicas de aprendizaje supervisado y no supervisado para analizar logs de ataques, patrones de explotación e incidencias registradas en APIs con alta exposición. Su análisis de clustering permitió identificar grupos de vulnerabilidades recurrentes, y un modelo de clasificación alcanzó una efectividad del 79% al predecir incidentes futuros de seguridad, demostrando que el ML puede anticipar comportamientos maliciosos y apoyar la mitigación temprana.
En el mismo sentido, Yeongah et al. (2022) emplearon modelos como regresión logística, Random Forest y XGBoost para predecir la aparición de vulnerabilidades críticas en APIs con grandes volúmenes de solicitudes. Entre ellos, XGBoost obtuvo el mejor desempeño con una precisión del 77.1%, validando su utilidad para identificar riesgos complejos que involucran múltiples variables asociadas a la arquitectura API. Por otro lado, Iqbal et al. (2024) desarrollaron un enfoque basado en Machine Learning para predecir costos operativos asociados a fallas de seguridad en sistemas API. Utilizaron modelos como KNN, regresión logística, árboles de decisión y Random Forest, siendo este último el más preciso con un RMSE de 1179.1 y un R² de 0.96. Sus resultados mostraron que ML no solo mejora la detección de vulnerabilidades, sino que también permite estimar costos potenciales derivados de ataques exitosos.
De forma complementaria, Sazzad (2023) aplicó modelos como XGBoost, Lasso Regression, Ridge Regression, Random Forest y KNN para predecir incidentes de seguridad en APIs. El modelo XGBoost obtuvo un R² de 0.8681, lo que demostró su eficacia para predecir escenarios de riesgo a partir de grandes volúmenes de datos de auditorías previas. Carreira et al. (2021) compararon múltiples modelos —Linear Regression, Ridge, Lasso, Elastic Net, KNN, Simple Tree, Random Forest y XGBoost— para predecir fallas de seguridad y tiempos de explotación. XGBoost destacó en precisión general, mientras que Simple Tree sobresalió en velocidad computacional, mostrando que los modelos más ligeros son útiles para análisis en tiempo real durante auditorías automatizadas. Finalmente, Keshav et al. (2022) desarrollaron un modelo basado en redes neuronales artificiales (ANN) para predecir puntos débiles en arquitecturas API, obteniendo una precisión del 92.72%, demostrando que las ANN pueden superar a modelos tradicionales cuando se requiere identificar patrones complejos de vulnerabilidades. Hassan et al. (2021) también aplicaron técnicas avanzadas de inteligencia computacional —como SVR, XGBoost, Random Forest y Stochastic Gradient Boosting— para predecir incidentes y costos derivados de fallas críticas en APIs, siendo SGB el modelo más preciso con una efectividad del 86%.
En conjunto, estos antecedentes internacionales fortalecen el sustento teórico y tecnológico para la aplicación de la metodología SEMMA y modelos de Machine Learning en la auditoría automatizada de APIs REST, demostrando que la predicción de vulnerabilidades, la clasificación OWASP API Top 10 y la reducción de costos operativos mediante análisis híbridos (SAST + DAST + ML) son enfoques eficientes, modernos y validados científicamente.

2.2	Marco Teórico
Machine Learning
Machine Learning (ML), según Sangacha et al. (2024), consiste en extraer conocimiento de los datos. Combina los campos de la estadística, la inteligencia artificial y la informática. El aprendizaje automático ha tenido un gran impacto en la forma en que se realiza la investigación basada en datos, especialmente en áreas como la gestión de recursos hídricos en la agricultura. En la actualidad, su popularidad crece, aplicándose en sectores como el reconocimiento de patrones climáticos o en la optimización de riego en cultivos, como se ve en aplicaciones agrícolas que predicen el estrés hídrico en función de las condiciones del suelo y el clima. Empresas y agricultores utilizan Machine Learning para mejorar las decisiones sobre la cantidad de agua a utilizar en sus cultivos.
El aprendizaje automático se basa en la generalización de patrones de datos históricos, y su objetivo es hacer predicciones sobre datos nuevos. Según Müller y Guido (2021), "en los albores del aprendizaje automático, comenzó como un conjunto de declaraciones if-else" (p. 1). Este enfoque mantenido manualmente funcionaba en sistemas simples, pero se volvía cada vez más complejo a medida que se añadían nuevas variables y condiciones. Un solo cambio en los datos de entrada podía requerir la reescritura completa del sistema. Este es uno de los problemas que resuelve el aprendizaje automático, pues automatiza el proceso de toma de decisiones basándose en ejemplos anteriores y puede generalizar patrones para adaptarse a nuevas situaciones, como cambios en las condiciones climáticas que afectan la disponibilidad de agua en los cultivos.
El aprendizaje profundo es un subcampo del aprendizaje automático que se ocupa de múltiples transformaciones entre representaciones de los datos, y se implementa frecuentemente mediante redes neuronales profundas (Bengio et al., 2023). Estas redes son especialmente útiles para detectar patrones complejos en grandes volúmenes de datos, como los generados por los sensores IoT en los cultivos, para predecir el estrés hídrico y gestionar el riego de manera eficiente. Los algoritmos de Machine Learning que se utilizan comúnmente en este campo incluyen aprendizaje supervisado y no supervisado.
Figura 2
Clasificación de los algoritmos de Machine Learning
Nota. Adaptado de Machine Learning Classification: Concepts, Models, Algorithms and more, por Kshitij Makwana y Satyapriya Chaudhari, 2023, Quantinsti (https://blog.quantinsti.com/machine-learning-classification/).

Castañeda et al. (2023) definen el aprendizaje supervisado como la entrega de pares de entrada y salida deseada al algoritmo, luego se construye un modelo basado en estos pares que se utiliza para hacer predicciones lo más precisas posibles sobre datos que son únicos y que el algoritmo no ha visto antes. Requiere cierto esfuerzo humano para construirlo y configurarlo, pero el objetivo es automatizarlo y, por lo tanto, ahorrar tiempo en tareas manuales monótonas o inviables.
Müller y Guido (2021) también mencionan dos subtipos de aprendizaje supervisado, el primero es la clasificación. El objetivo de la clasificación es predecir a qué categoría pertenece un punto de datos a partir de un conjunto de etiquetas predefinidas. Un ejemplo es un identificador de correo electrónico no deseado que etiqueta el correo entrante como legítimo o no deseado según un conjunto de reglas. Si el correo electrónico contiene suficientes términos o estructura típica del correo no deseado, o comparte suficientes similitudes con el correo no deseado visto anteriormente, se filtra automáticamente de la bandeja de entrada del usuario. El segundo subtipo mencionado por los autores es la regresión. Para los algoritmos de tipo regresión, el objetivo es predecir un número de puntos flotante (o un número real como se define en matemáticas).
En el aprendizaje no supervisado, solo se conocen los datos de entrada y se le pide al algoritmo que extraiga conocimiento de esta entrada. Existen varios tipos de algoritmos no supervisados. Castañeda et al. (2023) destacan las transformaciones no supervisadas y la agrupación no supervisada y describen sus características. La transformación consiste en representar los datos de una manera diferente que podría ser más fácil de entender para un ser humano u otros algoritmos de aprendizaje automático. 
Normalmente, la transformación se utiliza cuando los datos tienen demasiadas características para ser comprensibles al resumirlos con menos características. Esto se conoce comúnmente como reducir las dimensiones de los datos. En cuanto a los algoritmos de agrupación, el objetivo es dividir los puntos de datos en grupos distintos. El resultado es completamente desconocido de antemano, depende del algoritmo identificar patrones y crear algo significativo a partir de él. Un ejemplo es una funcionalidad que se encuentra a menudo en las plataformas de redes sociales que pueden reconocer a una persona al escanear fotos mediante reconocimiento facial. Una posible aplicación es agrupar estas fotos y formar un álbum, lo que podría ahorrar tiempo y potencialmente ser más preciso en comparación con si se hiciera manualmente. 

Análisis Híbrido de Seguridad en APIs REST
El análisis híbrido de seguridad constituye un enfoque integrado que combina las capacidades del análisis estático de seguridad de aplicaciones (SAST, por sus siglas en inglés Static Application Security Testing) con las del análisis dinámico de seguridad de aplicaciones (DAST, por sus siglas en inglés Dynamic Application Security Testing), con el propósito de maximizar la cobertura en la detección de vulnerabilidades y minimizar las limitaciones inherentes a cada técnica cuando se aplica de manera aislada. Este enfoque complementario permite aprovechar las fortalezas de ambas metodologías mientras se mitigan sus debilidades individuales.
Según Atlidakis et al. (2019), las técnicas tradicionales de análisis de seguridad presentan brechas significativas cuando se aplican individualmente. El análisis estático examina el código fuente, las especificaciones formales y las configuraciones sin ejecutar el sistema, permitiendo identificar patrones de código inseguro, configuraciones erróneas y violaciones de políticas de seguridad en etapas tempranas del desarrollo. Por su parte, el análisis dinámico evalúa el comportamiento de la aplicación en tiempo de ejecución mediante la ejecución de casos de prueba y la observación de respuestas del sistema, lo que permite validar la explotabilidad de vulnerabilidades potenciales y detectar fallas que emergen únicamente durante la interacción con el sistema (p. 587).
La integración de ambos enfoques permite aprovechar las fortalezas complementarias de SAST y DAST. Mientras el análisis estático proporciona conocimiento profundo sobre la estructura interna, las dependencias y la lógica de negocio implementada en las APIs REST, el análisis dinámico valida el comportamiento real del sistema bajo condiciones de ataque simulado, verificando si las vulnerabilidades potenciales identificadas estáticamente son efectivamente explotables en el contexto de ejecución. Chess y McGraw (2004) argumentan que esta combinación resulta fundamental para lograr evaluaciones de seguridad más completas y precisas en sistemas modernos (p. 78).
Análisis Estático de Seguridad de Aplicaciones (SAST)
El análisis estático de seguridad se define como el proceso de examinar el código fuente, el bytecode o las especificaciones declarativas de una aplicación sin ejecutarla, con el objetivo de identificar vulnerabilidades de seguridad, errores de programación y violaciones de estándares de codificación segura (Chess & West, 2007, p. 45). En el contexto específico de APIs REST, el análisis estático se aplica típicamente sobre especificaciones formales como OpenAPI (anteriormente conocido como Swagger) o RAML, que describen declarativamente la estructura, los endpoints, los parámetros, los esquemas de autenticación y las respuestas esperadas de la interfaz de programación.
Según Fielding (2000), el arquitecto de REST, las APIs REST deben adherirse a principios arquitectónicos específicos que incluyen la separación cliente-servidor, la ausencia de estado (statelessness), el cacheo, la interfaz uniforme y el sistema en capas. El análisis estático de especificaciones OpenAPI permite verificar el cumplimiento de estos principios y detectar desviaciones que pueden introducir vulnerabilidades de seguridad (p. 76).
El análisis SAST aplicado a especificaciones OpenAPI permite identificar múltiples categorías de vulnerabilidades del OWASP API Security Top 10 (OWASP Foundation, 2023). Entre las capacidades más significativas se encuentra la detección de configuraciones inseguras, donde el análisis puede identificar la ausencia de esquemas de autenticación en endpoints críticos, la exposición de información sensible en respuestas de error y configuraciones permisivas de CORS (Cross-Origin Resource Sharing) que permiten solicitudes desde cualquier origen.
Adicionalmente, mediante el examen de las definiciones de seguridad en OpenAPI, SAST puede detectar fallas de autenticación que incluyen endpoints que no requieren autenticación, esquemas de autenticación débiles como Basic Auth sin TLS, ausencia de mecanismos de rotación de tokens, y políticas inadecuadas de expiración de sesiones. Por otra parte, el análisis estático permite identificar patrones en los paths de endpoints que sugieren vulnerabilidades de autorización a nivel de objeto, como la exposición directa de identificadores de recursos sin validación de propiedad en la especificación.
La validación de esquemas de entrada constituye otra capacidad fundamental del análisis estático. SAST permite verificar la presencia y completitud de validaciones de esquema para parámetros de entrada, detectando la ausencia de restricciones de tipo, longitud, formato o valores permitidos que podrían resultar en ataques de inyección o manipulación de propiedades.

A pesar de sus capacidades, el análisis estático presenta limitaciones significativas documentadas en la literatura especializada. Chess y West (2007) señalan que SAST no puede validar si una vulnerabilidad potencial identificada en el código o en las especificaciones es efectivamente explotable en el contexto de ejecución real, ya que no considera el comportamiento dinámico del sistema, las configuraciones de entorno de producción, ni las interacciones con componentes externos como bases de datos, servicios de autenticación o API gateways (p. 52).
Análisis Dinámico de Seguridad de Aplicaciones (DAST)
El análisis dinámico de seguridad se define como el proceso de evaluar una aplicación en ejecución mediante la interacción con sus interfaces expuestas, enviando entradas diseñadas para provocar comportamientos anómalos, errores de seguridad o violaciones de políticas, y observando las respuestas del sistema para identificar vulnerabilidades explotables. En el contexto de APIs REST, DAST implica la ejecución automatizada de solicitudes HTTP contra endpoints activos, la manipulación de parámetros, la inyección de payloads maliciosos y el análisis de respuestas para detectar indicadores de vulnerabilidades.
Las técnicas DAST aplicadas a APIs REST incluyen el fuzzing de parámetros, que consiste en enviar entradas malformadas, excesivamente largas, con caracteres especiales o valores inesperados a los parámetros de las APIs para identificar comportamientos anómalos, errores de validación, divulgación de información sensible en mensajes de error o condiciones de denegación de servicio (Atlidakis et al., 2019, p. 589). Las pruebas de inyección constituyen otra técnica fundamental, mediante el envío de payloads diseñados para ejecutar inyecciones SQL, inyecciones de comandos, XSS (Cross-Site Scripting), LDAP injection u otras formas de inyección de código, verificando si las APIs procesan inadecuadamente entradas no sanitizadas (OWASP Foundation, 2023).
Las pruebas de autorización representan un componente crítico del análisis dinámico, mediante la ejecución de solicitudes con diferentes niveles de privilegios, manipulación de tokens de autenticación y modificación de identificadores de recursos en URLs y parámetros para verificar la existencia de vulnerabilidades de autorización como BOLA o BFLA (Broken Function Level Authorization). Adicionalmente, las pruebas de consumo de recursos implican el envío de solicitudes masivas, payloads de gran tamaño o solicitudes recursivas para identificar vulnerabilidades relacionadas con consumo no restringido de recursos y ausencia de mecanismos de rate limiting.
El escaneo pasivo constituye otra técnica relevante del análisis dinámico, mediante el análisis del tráfico HTTP interceptado para identificar información sensible expuesta en headers, cookies inseguras, configuraciones de CORS permisivas, versiones de software reveladas, y otros indicadores de configuraciones inseguras sin enviar solicitudes activas de ataque (Doupé et al., 2010, p. 156).
El análisis dinámico, pese a su capacidad para validar la explotabilidad de vulnerabilidades, presenta limitaciones documentadas extensamente. El DAST requiere que el sistema esté completamente implementado y desplegado en un entorno accesible, lo que limita su aplicación en etapas tempranas del desarrollo y genera dependencias de infraestructura. Atlidakis et al. (2019) identifican que el análisis dinámico tradicional opera sin conocimiento profundo de la estructura interna de las APIs, lo que resulta en cobertura incompleta de endpoints, incapacidad para identificar dependencias entre llamadas API que requieren secuencias específicas de operaciones, y dificultad para alcanzar estados profundos del sistema que solo son accesibles mediante flujos de interacción complejos (p. 593).
Integración de SAST y DAST: Enfoque Híbrido
La integración efectiva de análisis estático y dinámico constituye un área activa de investigación en seguridad de software. Según Chess y West (2007), el análisis híbrido permite superar las limitaciones de cada técnica individual mediante la correlación de hallazgos, la priorización de vulnerabilidades basada en evidencia combinada, y la dirección de pruebas dinámicas hacia áreas identificadas como de alto riesgo por el análisis estático (p. 58).
La literatura documenta múltiples modelos arquitectónicos para la integración de análisis estático y dinámico. El modelo secuencial representa un enfoque donde el análisis estático se ejecuta primero para identificar vulnerabilidades potenciales y áreas de código de alto riesgo, cuyos resultados se utilizan para configurar y dirigir el análisis dinámico subsecuente. Atlidakis et al. (2019) implementan este modelo en su herramienta RESTler, donde el análisis estático de especificaciones OpenAPI identifica dependencias entre endpoints y genera automáticamente secuencias de pruebas dinámicas que ejercitan estos flujos dependientes (p. 595).
El modelo paralelo ejecuta análisis estático y dinámico de manera concurrente e independiente, correlacionando posteriormente los hallazgos mediante técnicas de coincidencia de patrones, análisis de similitud y scoring de confianza. Este enfoque permite ejecutar ambos tipos de análisis sin dependencias temporales, maximizando la eficiencia del proceso de auditoría.
El modelo iterativo representa una aproximación donde los resultados del análisis estático y dinámico se retroalimentan mutuamente en ciclos iterativos. En cada iteración se refinan las pruebas y se mejora la precisión de la detección. Este modelo resulta particularmente efectivo para APIs con lógica de negocio compleja que requiere múltiples iteraciones para alcanzar cobertura completa.
Una contribución significativa del análisis híbrido contemporáneo es la aplicación de técnicas de Machine Learning para correlacionar hallazgos de SAST y DAST, reducir falsos positivos y priorizar vulnerabilidades. Sommer y Paxson (2010) documentan el uso de algoritmos de clasificación supervisada para predecir la probabilidad de que una vulnerabilidad identificada estáticamente sea explotable dinámicamente, basándose en características extraídas de patrones históricos de vulnerabilidades (p. 310).
La literatura documenta beneficios cuantificables del enfoque híbrido comparado con técnicas aisladas. Atlidakis et al. (2019) reportan incrementos significativos en la cantidad de vulnerabilidades únicas detectadas cuando se combina análisis estático de especificaciones OpenAPI con fuzzing dinámico inteligente, comparado con el uso de DAST tradicional sin guía estática (p. 598). La combinación de análisis estático y dinámico permite priorizar con mayor precisión las vulnerabilidades que representan riesgos reales y explotables, mejorando la eficiencia de los procesos de remediación comparado con enfoques que priorizan basándose únicamente en severidad CVSS.
Chess y West (2007) argumentan que el análisis híbrido permite el mejor de ambos mundos: detección temprana de vulnerabilidades potenciales mediante SAST en etapas de desarrollo, y validación de explotabilidad mediante DAST antes del despliegue en producción (p. 61).
A pesar de sus beneficios, la implementación de análisis híbrido presenta desafíos técnicos y operacionales documentados. La correlación efectiva de hallazgos de SAST y DAST requiere el desarrollo de heurísticas sofisticadas para emparejar vulnerabilidades identificadas en diferentes representaciones del sistema, lo que introduce complejidad técnica significativa. La ejecución combinada de análisis estático exhaustivo y pruebas dinámicas comprensivas puede requerir recursos computacionales sustanciales, particularmente para APIs con gran cantidad de endpoints y lógica de negocio compleja (Atlidakis et al., 2019, p. 601).
Aplicación del Análisis Híbrido al OWASP API Security Top 10
El OWASP API Security Project documenta las diez categorías de vulnerabilidades más críticas que afectan a las APIs modernas (OWASP Foundation, 2023). El análisis híbrido SAST + DAST contribuye significativamente a la detección de estas categorías mediante la complementariedad de sus capacidades.
Para la categoría Broken Object Level Authorization (BOLA), el análisis estático permite identificar patrones de exposición directa de identificadores de recursos sin controles de autorización en especificación OpenAPI, mientras que el análisis dinámico valida el acceso no autorizado a recursos mediante manipulación de identificadores en solicitudes reales. La integración de ambos enfoques permite la detección estática de endpoints susceptibles seguida de validación dinámica de explotabilidad, reduciendo significativamente los falsos positivos.
En el caso de Broken Authentication, SAST detecta esquemas de autenticación débiles, ausencia de autenticación en endpoints críticos y políticas inadecuadas de tokens en la especificación, mientras que DAST ejecuta pruebas de bypass de autenticación, fuerza bruta de credenciales y manipulación de tokens JWT en el sistema en ejecución. La combinación permite identificar configuraciones inseguras y validar la explotabilidad de mecanismos de autenticación implementados.
Para Broken Object Property Level Authorization, el análisis estático examina esquemas de datos para identificar propiedades sensibles expuestas sin restricciones, mientras que DAST ejecuta pruebas de mass assignment y sobre-extracción de propiedades sensibles en respuestas. La integración facilita la detección de campos sensibles seguida de validación de manipulación exitosa de propiedades.
Respecto a Unrestricted Resource Consumption, SAST identifica la ausencia de límites de rate, tamaño de payload y timeouts en especificación, mientras que DAST ejecuta pruebas de carga excesiva, payloads de gran tamaño y solicitudes recursivas para provocar denegación de servicio. El enfoque híbrido permite detectar ausencia de controles y validar el impacto real en recursos del sistema.
En Broken Function Level Authorization, el análisis estático identifica funciones administrativas expuestas sin controles de autorización adecuados, mientras que DAST ejecuta pruebas de escalada de privilegios y acceso a funciones administrativas con usuarios de bajo privilegio. La integración permite detectar endpoints administrativos y validar acceso no autorizado a funciones críticas.
Para Server Side Request Forgery (SSRF), el análisis estático identifica parámetros que aceptan URLs sin validación en especificación, mientras que DAST ejecuta pruebas de inyección de URLs maliciosas para acceder a recursos internos. La integración permite detectar parámetros susceptibles seguida de validación de explotabilidad real.
Para Security Misconfiguration, SAST proporciona detección exhaustiva de configuraciones inseguras como CORS permisivo, headers inseguros y métodos HTTP inadecuados, mientras que DAST valida el impacto de estas configuraciones en comportamiento real. El enfoque híbrido permite identificación completa de misconfigurations seguida de validación de explotabilidad práctica.
Esta integración sistemática de análisis estático y dinámico, fundamentada en la literatura especializada y validada empíricamente en investigaciones recientes, constituye el fundamento teórico del sistema HybridSecScan propuesto en la presente investigación.
SEMMA
Para los autores, la metodología es propuesta por SAS Institute y la describe como el modelo de selección y exploración de grandes cantidades de datos. El fin de SEMMA es encontrar patrones que sirvan de ayuda para las organizaciones. La metodología se basa en los modelos de minería de datos, por ello presenta cinco fases, las cuales se consideran fundamentales para alcanzar con éxito un proyecto: muestra, explorar, modificar, modelo, evaluar (Castañeda et al., 2023). 
Figura 3 
Fases del modelo de proceso SEMMA
Nota: Las cinco fases de la metodología SEMMA. De “A survey of data mining and knowledge discovery process models and methodologies”, por Mariscal et al., 2010, The Knowledge Engineering Review, 25(2), p. 144 (https://doi.org/10.1017/S0269888910000032)


En Sangacha et al. (2024) se describen las fases de la metodología SEMMA:
Fase I – “Muestreo (Sample)” → Extracción de una muestra representativa.
En esta primera fase de la metodología, se realiza la extracción de un conjunto de datos (población muestral) sobre la que se va a llevar a cabo el análisis. La muestra debe ser representativa de la población, caso contrario los resultados obtenidos no son válidos para el proceso en cuestión. El método de muestreo más común se denomina “muestreo aleatorio simple”, en el que cada elemento en la población tiene la misma probabilidad de ser seleccionado. En esta metodología, para cada una de las muestras escogidas se debe asociar un determinado nivel de confianza.
Fase II – “Exploración (Explore)” → Exploración de los datos de la muestra seleccionada.
En esta fase, se realiza un análisis de los datos extraídos en la muestra, para lo cual se propone el uso de herramientas de visualización o de diferentes técnicas estadísticas para la exploración de la información seleccionada, que contribuyan a poner de manifiesto relaciones entre variables. Esto permite simplificar el problema y optimizar la eficiencia del modelo, ayudando a refinar los procesos de descubrimiento de información en las fases subsiguientes del proceso en cuestión.
Fase III – “Modificación (Modify)” → Modificación de los datos.
La tercera fase de la metodología, involucra la modificación de los datos que van a ser ingresados al modelo para que tengan el formato adecuado, mejorando la definición de los mismos.
Fase IV – “Modelado (Model)” → Modelación de los datos.
En esta fase, se procede a modelar el conjunto de datos, permitiendo al software realizar una búsqueda completa de combinaciones de datos que ayudarán a predecir los resultados esperados de manera confiable. El objetivo de esta fase es establecer una relación entre las variables objeto del estudio y las variables explicativas, de manera tal que posibiliten inferir el valor de las mismas con un nivel de confianza determinado. Las técnicas utilizadas para el modelado de los datos incluyen técnicas adaptativas, lógica difusa, reglas de asociación, árboles de decisión, redes neuronales y computación evolutiva; como así también involucran métodos estadísticos tradicionales.
Fase V – “Valoración (Assess)” → Evaluación de los datos.
La última fase de la metodología SEMMA, consiste en la valoración de los datos obtenidos para determinar el grado de confiabilidad de los mismos y así poder evaluar el modelo, mediante la comparación con otros métodos estadísticos o con nuevas poblaciones muestrales.
Figura 4
Dinámica de la Metodología SEMMA 
Nota: La Dinámica de la Metodología SEMMA. De “Procesos De Explotacion De Informacion Basados En Sistemas Inteligentes”, por Britos, 2008, Universidad Nacional De La Plata Facultad De Informática, (p. 15)
En general, la metodología SEMMA se puede adaptar a cualquier proceso de minería de datos, además presenta un proceso iterativo e interactivo. La metodología se refiere al software del Instituto SAS. 
Tiempo de Inactividad
El tiempo de inactividad en el contexto de seguridad de APIs REST se refiere a los periodos en los que un servicio queda parcial o totalmente expuesto, inaccesible o degradado debido a vulnerabilidades no detectadas a tiempo o fallas en los mecanismos de protección. Este tiempo depende directamente de la capacidad del sistema de auditoría para identificar vulnerabilidades críticas y anomalías en el comportamiento de los endpoints mediante análisis híbridos (SAST + DAST) y modelos predictivos de Machine Learning. Las organizaciones que no cuentan con herramientas de detección temprana tienden a experimentar mayores demoras en la identificación y mitigación de fallas de seguridad, lo que incrementa el impacto operativo, la probabilidad de explotación y la percepción negativa del servicio por parte de los usuarios y equipos técnicos. Según Tapia T. (2019), en los procesos técnicos y administrativos de gestión de incidentes, se diferencian las actividades técnicas —como la identificación, clasificación y mitigación de vulnerabilidades— y las actividades administrativas —como el monitoreo continuo, priorización de alertas y asignación de recursos de seguridad—. Para optimizar estos procesos es indispensable estimar de manera precisa el tiempo de respuesta y los recursos necesarios para la resolución de hallazgos críticos, de modo que se reduzca el tiempo de exposición y se mejore la continuidad del servicio.
La investigación de Chambi Díaz y Jara Núñez (2020) demuestra que la ausencia de herramientas predictivas genera mayores niveles de insatisfacción en los usuarios debido a la lentitud en la mitigación de incidentes, lo que en un entorno de APIs puede traducirse en interrupciones de servicio, pérdida de integridad de datos o riesgo de explotación activa. En épocas de alta demanda, como picos de tráfico o despliegues frecuentes, la implementación de sistemas predictivos para la detección de vulnerabilidades permite reaccionar antes de que un ataque comprometa el servicio, manteniendo una operación estable incluso bajo condiciones de presión. De esta forma, los sistemas con análisis predictivo logran reducir el tiempo de inactividad asociado a fallas de seguridad y mitigar significativamente los riesgos asociados a la explotación de vulnerabilidades pertenecientes al OWASP API Top 10.
Costos Indirectos de Mantenimiento deteccion de vulnerabilidades
Los costos indirectos de mantenimiento en un entorno de APIs REST incluyen todos aquellos gastos que no provienen directamente de la remediación inmediata de vulnerabilidades, pero que afectan de manera sustancial la gestión de la seguridad y la operación del sistema. Entre ellos se encuentran el tiempo perdido de los desarrolladores y analistas de seguridad, la interrupción de procesos internos, los retrasos en despliegues, la pérdida de confianza de los usuarios y los costos operativos adicionales asociados con la atención de incidentes críticos. Estos costos forman parte significativa del impacto económico total, especialmente para organizaciones que dependen de operaciones continuas y despliegues ágiles. Según Iragorri et al. (2020), los costos indirectos asociados con la detección tardía de fallos en sistemas digitales suelen ser elevados, ya que implican un uso adicional de recursos, mayor tiempo de exposición y la necesidad de intervenciones correctivas de emergencia, afectando la eficiencia global del sistema.
De acuerdo con Lueckmann et al. (2019), los costos indirectos asociados a incidentes de seguridad pueden clasificarse en tres componentes principales:
Pérdida de productividad del servicio y del equipo técnico: Cuando una vulnerabilidad no se detecta a tiempo, el tiempo en que la API está expuesta o fuera de operación genera pérdidas significativas. El equipo técnico debe ejecutar revisiones manuales, corregir código y validar nuevamente el funcionamiento, lo que retrasa la entrega de nuevas funciones y afecta la continuidad operativa.
Tiempo no productivo de desarrolladores y analistas: Los equipos deben dedicar horas adicionales a corregir fallos críticos, ejecutar nuevos escaneos, validar parches y realizar pruebas, lo que impacta directamente la planificación y ejecución de proyectos. Este tiempo no planificado genera un efecto económico significativo, ya que recursos altamente especializados deben enfocarse en tareas reactivas que pudieron prevenirse con un sistema predictivo.
Gastos operativos adicionales: La atención de incidentes de seguridad puede implicar costos por servicios externos, desplazamientos de equipos, licencias adicionales, infraestructura para análisis forense y recursos especializados. Esto es aún más frecuente cuando las APIs se encuentran distribuidas en entornos híbridos o multicloud, donde la localización y revisión del incidente implica mayor complejidad.
Estos costos demuestran la necesidad de implementar modelos predictivos y herramientas de Machine Learning que permitan detectar y anticipar vulnerabilidades del OWASP API Top 10 antes de que se conviertan en incidentes explotables. La detección temprana reduce significativamente los tiempos de inactividad, optimiza la gestión del riesgo, minimiza los costos indirectos y fortalece la seguridad de las APIs mediante un enfoque preventivo y automatizado.
Número de Procedimientos
El número de procedimientos realizados en un proceso de auditoría de seguridad de APIs REST constituye un indicador crítico para estimar los costos operativos asociados a la detección y mitigación de vulnerabilidades. Cada hallazgo de seguridad —ya sea relacionado con inyecciones, fallas de autenticación, exposición de datos sensibles o cualquier otro riesgo del OWASP API Top 10— requiere un conjunto de intervenciones que pueden incluir revisiones manuales de código, ejecución de nuevos escaneos SAST o DAST, parches de seguridad, reconfiguraciones de infraestructura, actualizaciones de librerías o ajustes en las políticas de autorización. Tal como ocurre en sistemas industriales o agrícolas, donde cada incidente exige una acción correctiva, en el ámbito de seguridad informática el número de procedimientos influye directamente en los costos operativos, el tiempo requerido y el esfuerzo humano. Estudios como el de Lemhouer et al. (2019), aunque aplicados al mantenimiento agrícola, demuestran que la cantidad de intervenciones constituye un predictor clave de los costos operativos. En el contexto de APIs, un sistema predictivo basado en Machine Learning permite anticipar vulnerabilidades recurrentes, reducir el número de intervenciones reactivas y priorizar los procedimientos críticos, optimizando el esfuerzo del equipo de ciberseguridad.
Nivel de Eficiencia en la Detección de Vulnerabilidades OWASP API Top 10
El nivel de eficiencia en la detección de vulnerabilidades en APIs REST es un indicador fundamental que evalúa qué tan efectivo es el sistema para identificar riesgos antes de que afecten la disponibilidad, integridad o confidencialidad de los servicios. Al igual que la satisfacción del paciente refleja la calidad de atención médica, la eficiencia en la detección de vulnerabilidades refleja la calidad del servicio de auditoría automatizada y la confiabilidad del sistema de seguridad. Esta eficiencia depende de la precisión de los modelos predictivos, la efectividad del análisis híbrido (SAST + DAST), la tasa de falsos positivos y la rapidez con la que el sistema detecta y clasifica vulnerabilidades críticas. Según Mehta et al. (2020), diversos factores —como el tiempo de inactividad, la calidad del diagnóstico y la eficiencia en la respuesta— influyen directamente en la percepción del usuario final sobre un sistema; trasladado a nuestro contexto, estos factores influyen en la percepción del equipo de desarrollo y operaciones respecto a la utilidad del sistema de auditoría.
Tiempo de Inactividad: La demora entre la aparición de una vulnerabilidad y su detección puede generar riesgos severos, interrupciones operativas y pérdida de confianza. Un modelo predictivo eficaz minimiza estos tiempos, permitiendo anticipar comportamientos anómalos, prevenir rutas de explotación y reducir la exposición.
Calidad de la Detección: La precisión para identificar vulnerabilidades reales —sin sobrecargar al equipo con falsos positivos— es esencial. Un sistema basado en ML que detecta fallas de manera temprana, consistente y sin ruido mejora la credibilidad del sistema, reduce la carga operativa y fortalece la seguridad de la API.
Eficiencia Operativa: La capacidad del sistema para facilitar la resolución rápida de vulnerabilidades y orientar los esfuerzos en los riesgos más críticos eleva la productividad del equipo y optimiza el ciclo DevSecOps. Un sistema eficiente contribuye a una entrega continua más segura, igual que en salud un buen tratamiento garantiza mejores resultados.
Estudios como los de Mehta et al. (2020) evidencian que la eficiencia en la detección está directamente relacionada con la continuidad operativa y la satisfacción del usuario. En el ámbito de APIs, una alta eficiencia en la detección reduce riesgos, fortalece la resiliencia del sistema y disminuye costos operativos. Así como un agricultor se siente más confiado cuando un sistema detecta el estrés hídrico de forma precisa, los equipos de desarrollo y seguridad confían más en un sistema que detecta vulnerabilidades OWASP API Top 10 con alta precisión, mínima latencia y baja tasa de error. En este sentido, los modelos predictivos fortalecen la protección de datos, mejoran la estabilidad del servicio y contribuyen a una percepción positiva del sistema de auditoría automatizada.



CAPÍTULO III: CONSTRUCCIÓN DE LA SOLUCIÓN DE MACHINE LEARNING CON ANALISIS LEARNING CON ANÁLISIS HÍBRDO (SAST + DAST)
3.1	Distribución de Solución
La creciente complejidad de las arquitecturas basadas en APIs REST, sumada al incremento de ataques dirigidos a interfaces de comunicación, ha convertido la seguridad de APIs en un eje fundamental dentro de los ecosistemas empresariales modernos. En particular, las vulnerabilidades catalogadas en el OWASP API Top 10 —como fallas de autenticación, exposición de datos sensibles, inyecciones, mala configuración de seguridad o escalamiento de privilegios— representan los principales vectores de compromiso que afectan la disponibilidad, integridad y confidencialidad de los servicios digitales. Ante este contexto, la integración de técnicas avanzadas de análisis híbrido, combinando SAST (Static Application Security Testing) y DAST (Dynamic Application Security Testing) con modelos de Machine Learning, permite no solo detectar vulnerabilidades existentes, sino anticipar patrones de riesgo antes de que sean explotados.
El presente estudio tiene como finalidad aplicar la metodología SEMMA —acrónimo de Sample, Explore, Modify, Model, Assess— para desarrollar un sistema de auditoría automatizada orientado a la detección predictiva de vulnerabilidades OWASP API Top 10 en APIs REST. Este sistema integrará datos procedentes de escáneres estáticos y dinámicos, logs de interacción, patrones de tráfico y métricas de comportamiento, los cuales serán utilizados para entrenar un modelo capaz de clasificar, predecir y priorizar posibles fallas de seguridad en tiempo real.
La metodología SEMMA fue seleccionada por su naturaleza estructurada y orientada a proyectos de minería de datos de alto volumen, así como por su capacidad para adaptarse a entornos de seguridad donde la complejidad técnica y la heterogeneidad de los datos requieren una secuencia ordenada y rigurosa. A diferencia de otras metodologías, SEMMA garantiza un flujo lógico que inicia con la toma de muestras y exploración de la información generada por herramientas de seguridad, avanza con la transformación y preparación de los datos para entrenamiento, continúa con la construcción del modelo de Machine Learning y culmina con su evaluación y validación operativa dentro del sistema de auditoría automatizada.

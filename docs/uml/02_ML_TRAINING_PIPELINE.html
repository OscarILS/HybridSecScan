<!DOCTYPE html><html><head>
      <title>02_ML_TRAINING_PIPELINE</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="file:///c:\Users\oscar\.vscode\extensions\shd101wyy.markdown-preview-enhanced-0.8.20\crossnote\dependencies\katex\katex.min.css">
      
      
      <script type="text/javascript" src="file:///c:\Users\oscar\.vscode\extensions\shd101wyy.markdown-preview-enhanced-0.8.20\crossnote\dependencies\mermaid\mermaid.min.js" charset="UTF-8"></script>
      
      
      <style>
      code[class*=language-],pre[class*=language-]{color:#333;background:0 0;font-family:Consolas,"Liberation Mono",Menlo,Courier,monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.4;-moz-tab-size:8;-o-tab-size:8;tab-size:8;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:.8em;overflow:auto;border-radius:3px;background:#f5f5f5}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal;background:#f5f5f5}.token.blockquote,.token.comment{color:#969896}.token.cdata{color:#183691}.token.doctype,.token.macro.property,.token.punctuation,.token.variable{color:#333}.token.builtin,.token.important,.token.keyword,.token.operator,.token.rule{color:#a71d5d}.token.attr-value,.token.regex,.token.string,.token.url{color:#183691}.token.atrule,.token.boolean,.token.code,.token.command,.token.constant,.token.entity,.token.number,.token.property,.token.symbol{color:#0086b3}.token.prolog,.token.selector,.token.tag{color:#63a35c}.token.attr-name,.token.class,.token.class-name,.token.function,.token.id,.token.namespace,.token.pseudo-class,.token.pseudo-element,.token.url-reference .token.variable{color:#795da3}.token.entity{cursor:help}.token.title,.token.title .token.punctuation{font-weight:700;color:#1d3e81}.token.list{color:#ed6a43}.token.inserted{background-color:#eaffea;color:#55a532}.token.deleted{background-color:#ffecec;color:#bd2c00}.token.bold{font-weight:700}.token.italic{font-style:italic}.language-json .token.property{color:#183691}.language-markup .token.tag .token.punctuation{color:#333}.language-css .token.function,code.language-css{color:#0086b3}.language-yaml .token.atrule{color:#63a35c}code.language-yaml{color:#183691}.language-ruby .token.function{color:#333}.language-markdown .token.url{color:#795da3}.language-makefile .token.symbol{color:#795da3}.language-makefile .token.variable{color:#183691}.language-makefile .token.builtin{color:#0086b3}.language-bash .token.keyword{color:#0086b3}pre[data-line]{position:relative;padding:1em 0 1em 3em}pre[data-line] .line-highlight-wrapper{position:absolute;top:0;left:0;background-color:transparent;display:block;width:100%}pre[data-line] .line-highlight{position:absolute;left:0;right:0;padding:inherit 0;margin-top:1em;background:hsla(24,20%,50%,.08);background:linear-gradient(to right,hsla(24,20%,50%,.1) 70%,hsla(24,20%,50%,0));pointer-events:none;line-height:inherit;white-space:pre}pre[data-line] .line-highlight:before,pre[data-line] .line-highlight[data-end]:after{content:attr(data-start);position:absolute;top:.4em;left:.6em;min-width:1em;padding:0 .5em;background-color:hsla(24,20%,50%,.4);color:#f4f1ef;font:bold 65%/1.5 sans-serif;text-align:center;vertical-align:.3em;border-radius:999px;text-shadow:none;box-shadow:0 1px #fff}pre[data-line] .line-highlight[data-end]:after{content:attr(data-end);top:auto;bottom:.4em}html body{font-family:'Helvetica Neue',Helvetica,'Segoe UI',Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ol,html body>ul{margin-bottom:16px}html body ol,html body ul{padding-left:2em}html body ol.no-list,html body ul.no-list{padding:0;list-style-type:none}html body ol ol,html body ol ul,html body ul ol,html body ul ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:700;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:700}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::after,html body code::before{letter-spacing:-.2em;content:'\00a0'}html body pre>code{padding:0;margin:0;word-break:normal;white-space:pre;background:0 0;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:after,html body pre code:before,html body pre tt:after,html body pre tt:before{content:normal}html body blockquote,html body dl,html body ol,html body p,html body pre,html body ul{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body code,html body pre{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview ul{list-style:disc}.markdown-preview ul ul{list-style:circle}.markdown-preview ul ul ul{list-style:square}.markdown-preview ol{list-style:decimal}.markdown-preview ol ol,.markdown-preview ul ol{list-style-type:lower-roman}.markdown-preview ol ol ol,.markdown-preview ol ul ol,.markdown-preview ul ol ol,.markdown-preview ul ul ol{list-style-type:lower-alpha}.markdown-preview .newpage,.markdown-preview .pagebreak{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center!important}.markdown-preview:not([data-for=preview]) .code-chunk .code-chunk-btn-group{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .status{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .output-div{margin-bottom:16px}.markdown-preview .md-toc{padding:0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link div,.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}.markdown-preview .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0;min-height:100vh}@media screen and (min-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{font-size:14px!important;padding:1em}}@media print{html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc{padding:0 16px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link div,html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% - 300px);padding:2em calc(50% - 457px - 300px / 2);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
      <!-- The content below will be included at the end of the <head> element. --><script type="text/javascript">
  document.addEventListener("DOMContentLoaded", function () {
    // your code here
  });
</script></head><body for="html-export">
    
    
      <div class="crossnote markdown-preview  ">
      
<h1 id="pipeline-de-entrenamiento-del-modelo-ml">Pipeline de Entrenamiento del Modelo ML </h1>
<h2 id="documentaci√≥n-uml-para-el-sistema-de-machine-learning">Documentaci√≥n UML para el Sistema de Machine Learning </h2>
<blockquote>
<p><strong>Autor:</strong> Oscar Isaac Laguna Santa Cruz<br>
<strong>Co-Autor</strong>: Kenneth Evander Ortega Mor√°n<br>
<strong>Instituci√≥n:</strong> Universidad Nacional Mayor de San Marcos<br>
<strong>Fecha:</strong> Noviembre 2025<br>
<strong>Versi√≥n:</strong> 1.0</p>
</blockquote>
<hr>
<h2 id="√≠ndice">√çndice </h2>
<ol>
<li><a href="#1-vista-general-del-pipeline">Vista General del Pipeline</a></li>
<li><a href="#2-diagrama-de-flujo-del-entrenamiento">Diagrama de Flujo del Entrenamiento</a></li>
<li><a href="#3-descripci%C3%B3n-detallada-del-pipeline">Descripci√≥n Detallada del Pipeline</a></li>
<li><a href="#4-diagrama-de-secuencia-del-entrenamiento">Diagrama de Secuencia</a></li>
<li><a href="#5-diagrama-de-clases-del-pipeline-ml">Diagrama de Clases</a></li>
<li><a href="#6-m%C3%A9tricas-de-evaluaci%C3%B3n-del-modelo">M√©tricas de Evaluaci√≥n</a></li>
<li><a href="#7-consideraciones-para-tesis">Consideraciones para Tesis</a></li>
<li><a href="#8-ejemplo-de-uso-del-modelo-entrenado">Ejemplo de Uso</a></li>
</ol>
<hr>
<h2 id="1-vista-general-del-pipeline">1. Vista General del Pipeline </h2>
<p>El sistema HybridSecScan implementa un pipeline de Machine Learning para entrenar el modelo de correlaci√≥n de vulnerabilidades SAST-DAST. Este pipeline procesa datos reales de NVD (National Vulnerability Database) y genera un clasificador Random Forest con m√©tricas de alta precisi√≥n.</p>
<h3 id="datos-procesados">Datos Procesados </h3>
<ul>
<li><strong>318,956 CVEs</strong> de NVD (2002-2025)</li>
<li><strong>96,983 registros</strong> de correlaci√≥n SAST-DAST</li>
<li><strong>517 features</strong> (TF-IDF + categ√≥ricas + num√©ricas)</li>
<li><strong>Split 80/10/10</strong> (Training/Validation/Test)</li>
</ul>
<h3 id="modelo-resultante">Modelo Resultante </h3>
<ul>
<li><strong>Algoritmo:</strong> Random Forest (200 √°rboles)</li>
<li><strong>Accuracy:</strong> 100%</li>
<li><strong>F1-Score:</strong> 100%</li>
<li><strong>ROC-AUC:</strong> 1.0000</li>
</ul>
<hr>
<h2 id="2-diagrama-de-flujo-del-entrenamiento">2. Diagrama de Flujo del Entrenamiento </h2>
<div class="mermaid">flowchart TB
    Start([üöÄ Inicio Pipeline ML])
    
    %% ======================
    %% FASE 1: DESCARGA DATOS
    %% ======================
    subgraph Phase1["FASE 1: ADQUISICI√ìN DE DATOS"]
        Download[üì• Descargar CVEs desde NVD&lt;br/&gt;Archivos JSON 2002-2025&lt;br/&gt;Total: 24 archivos]
        ValidateJSON{‚úÖ ¬øArchivos&lt;br/&gt;v√°lidos?}
        ErrorDownload[‚ùå Error de Descarga&lt;br/&gt;Reintentar o usar backup]
    end
    
    %% ======================
    %% FASE 2: PROCESAMIENTO
    %% ======================
    subgraph Phase2["FASE 2: PROCESAMIENTO DE DATOS"]
        LoadJSON[üìÇ Cargar JSON Files&lt;br/&gt;data/raw/nvd/*.json]
        ParseCVE[üîç Parsear CVE Items&lt;br/&gt;Extraer: ID, CWE, Severidad,&lt;br/&gt;Descripci√≥n, Referencias]
        
        subgraph ExtractFeatures["Extracci√≥n de Caracter√≠sticas"]
            ExtractCWE[Extraer CWE-IDs&lt;br/&gt;Ej: CWE-89, CWE-79]
            ExtractSeverity[Extraer CVSS Score&lt;br/&gt;Critical/High/Medium/Low]
            ExtractDesc[Extraer Descripci√≥n&lt;br/&gt;Texto en ingl√©s]
            NormalizeSeverity[Normalizar Severidad&lt;br/&gt;CRITICAL ‚Üí HIGH&lt;br/&gt;NONE ‚Üí INFO]
        end
        
        GenerateCorrelations[üîÑ Generar Correlaciones&lt;br/&gt;SAST-DAST Sint√©ticas&lt;br/&gt;Basadas en CWE patterns]
        
        subgraph CorrelationLogic["L√≥gica de Correlaci√≥n"]
            CheckSAST{¬øCWE detectable&lt;br/&gt;por SAST?}
            CheckDAST{¬øCWE detectable&lt;br/&gt;por DAST?}
            AssignLabel[Asignar Label&lt;br/&gt;is_correlated: 1 o 0]
            CalcConfidence[Calcular Confidence&lt;br/&gt;Score: 0.0-1.0]
        end
        
        CreateDataFrame[üìä Crear DataFrame&lt;br/&gt;Pandas con 18 columnas]
        
        ValidateData{‚úÖ ¬øDatos&lt;br/&gt;consistentes?}
        ErrorProcess[‚ùå Error de Procesamiento&lt;br/&gt;Revisar formato JSON]
    end
    
    %% ======================
    %% FASE 3: SPLIT DATASET
    %% ======================
    subgraph Phase3["FASE 3: DIVISI√ìN DE DATOS"]
        ShuffleData[üîÄ Shuffle Dataset&lt;br/&gt;random_state=42]
        SplitData[‚úÇÔ∏è Split 80/10/10&lt;br/&gt;Train/Val/Test]
        
        subgraph Splits["Conjuntos Resultantes"]
            TrainSet[üìö Training Set&lt;br/&gt;77,586 muestras 80%]
            ValSet[üìù Validation Set&lt;br/&gt;9,698 muestras 10%]
            TestSet[üß™ Test Set&lt;br/&gt;9,699 muestras 10%]
        end
        
        SaveCSV[üíæ Guardar CSV&lt;br/&gt;data/processed/]
        
        ValidateSplit{‚úÖ ¬øSplit&lt;br/&gt;balanceado?}
    end
    
    %% ======================
    %% FASE 4: FEATURE ENGINEERING
    %% ======================
    subgraph Phase4["FASE 4: INGENIER√çA DE FEATURES"]
        LoadCSV[üìÇ Cargar CSVs&lt;br/&gt;Training/Validation/Test]
        
        subgraph TextFeatures["Features Textuales"]
            CombineText[Combinar Descripciones&lt;br/&gt;SAST + DAST]
            TFIDF[TF-IDF Vectorization&lt;br/&gt;max_features=500&lt;br/&gt;ngram_range=1,2]
            FitTFIDF{¬øFit o&lt;br/&gt;Transform?}
            FitVectorizer[Fit en Training&lt;br/&gt;Crear vocabulario]
            TransformVectorizer[Transform en Val/Test&lt;br/&gt;Usar vocabulario existente]
        end
        
        subgraph CategoricalFeatures["Features Categ√≥ricas"]
            EncodeCat[Label Encoding&lt;br/&gt;8 columnas categ√≥ricas]
            TypeEncode[Encode sast_type&lt;br/&gt;dast_type]
            SeverityEncode[Encode sast_severity&lt;br/&gt;dast_severity]
            CWEEncode[Encode sast_cwe&lt;br/&gt;dast_cwe]
            ToolEncode[Encode sast_tool&lt;br/&gt;dast_tool]
        end
        
        subgraph NumericFeatures["Features Num√©ricas"]
            TypeMatch[Type Match 0/1]
            CWEMatch[CWE Match 0/1]
            SevMatch[Severity Match 0/1]
            DescLength[Description Length]
            FileDepth[File/Endpoint Depth]
            LineNumber[SAST Line Number]
        end
        
        ConcatFeatures[üîó Concatenar Features&lt;br/&gt;TF-IDF + Categorical + Numeric&lt;br/&gt;Total: 517 features]
        
        ValidateFeatures{‚úÖ ¬øTodas las&lt;br/&gt;features v√°lidas?}
        ErrorFeatures[‚ùå Error en Features&lt;br/&gt;Revisar NaN/Inf]
    end
    
    %% ======================
    %% FASE 5: ENTRENAMIENTO
    %% ======================
    subgraph Phase5["FASE 5: ENTRENAMIENTO DEL MODELO"]
        InitRF[üå≤ Inicializar Random Forest&lt;br/&gt;n_estimators=200&lt;br/&gt;max_depth=20&lt;br/&gt;class_weight=balanced]
        
        FitModel[üìö Entrenar Modelo&lt;br/&gt;X_train, y_train&lt;br/&gt;n_jobs=-1 paralelo]
        
        subgraph Training["Proceso de Entrenamiento"]
            BuildTrees[Construir 200 √Årboles&lt;br/&gt;Bootstrap sampling]
            SelectFeatures[Feature Selection&lt;br/&gt;sqrt features por split]
            GrowTree[Crecer √Årboles&lt;br/&gt;hasta max_depth=20]
            PruneTree[Pruning&lt;br/&gt;min_samples_leaf=5]
        end
        
        ModelTrained[‚úÖ Modelo Entrenado&lt;br/&gt;200 √°rboles completos]
    end
    
    %% ======================
    %% FASE 6: EVALUACI√ìN
    %% ======================
    subgraph Phase6["FASE 6: EVALUACI√ìN Y VALIDACI√ìN"]
        PredictVal[üîÆ Predicci√≥n Validation&lt;br/&gt;y_val_pred]
        PredictTest[üîÆ Predicci√≥n Test&lt;br/&gt;y_test_pred]
        
        subgraph Metrics["C√°lculo de M√©tricas"]
            CalcAccuracy[Accuracy Score]
            CalcPrecision[Precision Score]
            CalcRecall[Recall Score]
            CalcF1[F1-Score]
            CalcROCAUC[ROC-AUC Score]
            ConfMatrix[Confusion Matrix&lt;br/&gt;TP/TN/FP/FN]
        end
        
        ValidateMetrics{‚úÖ M√©tricas&lt;br/&gt;aceptables?&lt;br/&gt;F1 &gt; 0.85}
        
        AcceptModel[‚úÖ Modelo Aceptado&lt;br/&gt;F1=1.00, AUC=1.00]
        RejectModel[‚ùå Modelo Rechazado&lt;br/&gt;Ajustar hiperpar√°metros]
        
        FeatureImportance[üìä Feature Importance&lt;br/&gt;Top 15 features m√°s importantes]
        GenerateReport[üìù Generar Reporte&lt;br/&gt;Classification Report]
    end
    
    %% ======================
    %% FASE 7: PERSISTENCIA
    %% ======================
    subgraph Phase7["FASE 7: GUARDADO DEL MODELO"]
        PackageModel[üì¶ Empaquetar Modelo&lt;br/&gt;classifier + vectorizer&lt;br/&gt;+ encoders + metadata]
        
        SaveModel[üíæ Guardar PKL&lt;br/&gt;rf_correlator_v1.pkl&lt;br/&gt;usando joblib]
        
        SaveMetadata[üíæ Guardar Metadata&lt;br/&gt;metadata.json&lt;br/&gt;m√©tricas + info]
        
        ValidateSave{‚úÖ ¬øGuardado&lt;br/&gt;exitoso?}
        ErrorSave[‚ùå Error al Guardar&lt;br/&gt;Verificar permisos]
    end
    
    %% ======================
    %% FIN
    %% ======================
    End([üèÅ Pipeline Completado&lt;br/&gt;Modelo Listo para Producci√≥n])
    
    %% ================================
    %% FLUJO PRINCIPAL
    %% ================================
    Start --&gt; Download
    Download --&gt; ValidateJSON
    ValidateJSON --&gt;|S√≠| LoadJSON
    ValidateJSON --&gt;|No| ErrorDownload
    ErrorDownload --&gt; Download
    
    LoadJSON --&gt; ParseCVE
    ParseCVE --&gt; ExtractCWE
    ExtractCWE --&gt; ExtractSeverity
    ExtractSeverity --&gt; ExtractDesc
    ExtractDesc --&gt; NormalizeSeverity
    NormalizeSeverity --&gt; GenerateCorrelations
    
    GenerateCorrelations --&gt; CheckSAST
    CheckSAST --&gt;|S√≠| CheckDAST
    CheckSAST --&gt;|No| CheckDAST
    CheckDAST --&gt; AssignLabel
    AssignLabel --&gt; CalcConfidence
    CalcConfidence --&gt; CreateDataFrame
    
    CreateDataFrame --&gt; ValidateData
    ValidateData --&gt;|S√≠| ShuffleData
    ValidateData --&gt;|No| ErrorProcess
    ErrorProcess --&gt; ParseCVE
    
    ShuffleData --&gt; SplitData
    SplitData --&gt; TrainSet
    SplitData --&gt; ValSet
    SplitData --&gt; TestSet
    TrainSet &amp; ValSet &amp; TestSet --&gt; SaveCSV
    
    SaveCSV --&gt; ValidateSplit
    ValidateSplit --&gt;|S√≠| LoadCSV
    ValidateSplit --&gt;|No| ShuffleData
    
    LoadCSV --&gt; CombineText
    CombineText --&gt; TFIDF
    TFIDF --&gt; FitTFIDF
    FitTFIDF --&gt;|Fit Training| FitVectorizer
    FitTFIDF --&gt;|Transform Val/Test| TransformVectorizer
    FitVectorizer --&gt; EncodeCat
    TransformVectorizer --&gt; EncodeCat
    
    EncodeCat --&gt; TypeEncode
    TypeEncode --&gt; SeverityEncode
    SeverityEncode --&gt; CWEEncode
    CWEEncode --&gt; ToolEncode
    ToolEncode --&gt; TypeMatch
    
    TypeMatch --&gt; CWEMatch
    CWEMatch --&gt; SevMatch
    SevMatch --&gt; DescLength
    DescLength --&gt; FileDepth
    FileDepth --&gt; LineNumber
    LineNumber --&gt; ConcatFeatures
    
    ConcatFeatures --&gt; ValidateFeatures
    ValidateFeatures --&gt;|S√≠| InitRF
    ValidateFeatures --&gt;|No| ErrorFeatures
    ErrorFeatures --&gt; CombineText
    
    InitRF --&gt; FitModel
    FitModel --&gt; BuildTrees
    BuildTrees --&gt; SelectFeatures
    SelectFeatures --&gt; GrowTree
    GrowTree --&gt; PruneTree
    PruneTree --&gt; ModelTrained
    
    ModelTrained --&gt; PredictVal
    PredictVal --&gt; PredictTest
    PredictTest --&gt; CalcAccuracy
    CalcAccuracy --&gt; CalcPrecision
    CalcPrecision --&gt; CalcRecall
    CalcRecall --&gt; CalcF1
    CalcF1 --&gt; CalcROCAUC
    CalcROCAUC --&gt; ConfMatrix
    
    ConfMatrix --&gt; ValidateMetrics
    ValidateMetrics --&gt;|S√≠| AcceptModel
    ValidateMetrics --&gt;|No| RejectModel
    RejectModel --&gt; InitRF
    
    AcceptModel --&gt; FeatureImportance
    FeatureImportance --&gt; GenerateReport
    GenerateReport --&gt; PackageModel
    
    PackageModel --&gt; SaveModel
    SaveModel --&gt; SaveMetadata
    SaveMetadata --&gt; ValidateSave
    ValidateSave --&gt;|S√≠| End
    ValidateSave --&gt;|No| ErrorSave
    ErrorSave --&gt; SaveModel
    
    %% ================================
    %% ESTILOS
    %% ================================
    classDef phaseStyle fill:#e3f2fd,stroke:#1976d2,stroke-width:3px
    classDef processStyle fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    classDef decisionStyle fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    classDef errorStyle fill:#ffebee,stroke:#c62828,stroke-width:2px
    classDef successStyle fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px
    classDef dataStyle fill:#e0f2f1,stroke:#00695c,stroke-width:2px
    
    class Phase1,Phase2,Phase3,Phase4,Phase5,Phase6,Phase7 phaseStyle
    class Download,ParseCVE,GenerateCorrelations,CreateDataFrame,ShuffleData,SplitData,LoadCSV,CombineText,TFIDF,EncodeCat,ConcatFeatures,InitRF,FitModel,PredictVal,PredictTest,PackageModel,SaveModel,SaveMetadata processStyle
    class ValidateJSON,ValidateData,ValidateSplit,FitTFIDF,ValidateFeatures,ValidateMetrics,CheckSAST,CheckDAST,ValidateSave decisionStyle
    class ErrorDownload,ErrorProcess,ErrorFeatures,ErrorSave,RejectModel errorStyle
    class AcceptModel,ModelTrained,End successStyle
    class TrainSet,ValSet,TestSet,SaveCSV dataStyle
</div><hr>
<h2 id="3-descripci√≥n-detallada-del-pipeline">3. Descripci√≥n Detallada del Pipeline </h2>
<h3 id="fase-1-adquisici√≥n-de-datos">FASE 1: Adquisici√≥n de Datos </h3>
<ul>
<li><strong>Fuente:</strong> National Vulnerability Database (NVD)</li>
<li><strong>Formato:</strong> JSON files (API v2.0)</li>
<li><strong>Per√≠odo:</strong> 2002-2025 (24 archivos)</li>
<li><strong>Total CVEs:</strong> 318,956 vulnerabilidades</li>
</ul>
<h3 id="fase-2-procesamiento-de-datos">FASE 2: Procesamiento de Datos </h3>
<p><strong>Extracci√≥n de Caracter√≠sticas:</strong></p>
<ul>
<li>CVE ID (ej: CVE-2023-12345)</li>
<li>CWE-IDs (ej: CWE-89 SQL Injection)</li>
<li>CVSS Score y Severidad (Critical/High/Medium/Low)</li>
<li>Descripci√≥n en ingl√©s (limitada a 500 caracteres)</li>
</ul>
<p><strong>Generaci√≥n de Correlaciones:</strong></p>
<ul>
<li>Se simula detecci√≥n SAST/DAST basada en patrones CWE</li>
<li>CWEs detectables por SAST: CWE-89, CWE-79, CWE-78, CWE-22, etc.</li>
<li>CWEs detectables por DAST: CWE-89, CWE-79, CWE-352, CWE-434, etc.</li>
<li>Label <code>is_correlated=1</code> si ambos detectan la misma vulnerabilidad</li>
</ul>
<p><strong>Resultado:</strong> 96,983 registros de correlaci√≥n</p>
<h3 id="fase-3-divisi√≥n-de-datos">FASE 3: Divisi√≥n de Datos </h3>
<pre data-role="codeBlock" data-info="" class="language-text"><code>Training Set:   77,586 muestras (80.0%)
Validation Set:  9,698 muestras (10.0%)
Test Set:        9,699 muestras (10.0%)
</code></pre><p><strong>Estrategia:</strong></p>
<ul>
<li>Shuffle con <code>random_state=42</code> para reproducibilidad</li>
<li>Split estratificado manteniendo balance de clases</li>
<li>Distribuci√≥n: 60.2% correlacionadas, 39.8% no correlacionadas</li>
</ul>
<h3 id="fase-4-ingenier√≠a-de-features">FASE 4: Ingenier√≠a de Features </h3>
<p><strong>1. Features Textuales (TF-IDF):</strong></p>
<ul>
<li>Vectorizaci√≥n de descripciones SAST + DAST</li>
<li>500 features TF-IDF</li>
<li>N-gramas: unigrams + bigrams</li>
<li>Stop words: ingl√©s</li>
</ul>
<p><strong>2. Features Categ√≥ricas (Label Encoding):</strong></p>
<ul>
<li>sast_type, dast_type</li>
<li>sast_severity, dast_severity</li>
<li>sast_cwe, dast_cwe</li>
<li>sast_tool, dast_tool</li>
</ul>
<p><strong>3. Features Num√©ricas:</strong></p>
<ul>
<li>Type Match (binario)</li>
<li>CWE Match (binario)</li>
<li>Severity Match (binario)</li>
<li>Longitud de descripciones</li>
<li>Profundidad de archivos/endpoints</li>
<li>N√∫mero de l√≠nea (SAST)</li>
</ul>
<p><strong>Total:</strong> 517 features</p>
<h3 id="fase-5-entrenamiento-del-modelo">FASE 5: Entrenamiento del Modelo </h3>
<p><strong>Algoritmo:</strong> Random Forest Classifier</p>
<p><strong>Hiperpar√°metros:</strong></p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code>n_estimators<span class="token operator">=</span><span class="token number">200</span>          <span class="token comment"># N√∫mero de √°rboles</span>
max_depth<span class="token operator">=</span><span class="token number">20</span>              <span class="token comment"># Profundidad m√°xima</span>
min_samples_split<span class="token operator">=</span><span class="token number">10</span>      <span class="token comment"># M√≠nimo para split</span>
min_samples_leaf<span class="token operator">=</span><span class="token number">5</span>        <span class="token comment"># M√≠nimo en hoja</span>
max_features<span class="token operator">=</span><span class="token string">'sqrt'</span>       <span class="token comment"># Features por split</span>
class_weight<span class="token operator">=</span><span class="token string">'balanced'</span>   <span class="token comment"># Balanceo de clases</span>
random_state<span class="token operator">=</span><span class="token number">42</span>           <span class="token comment"># Reproducibilidad</span>
n_jobs<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span>                 <span class="token comment"># Paralelizaci√≥n</span>
</code></pre><p><strong>Justificaci√≥n del Algoritmo:</strong></p>
<ul>
<li><strong>Interpretabilidad:</strong> Feature importance analysis</li>
<li><strong>Robustez:</strong> Maneja datos mixtos (texto + categ√≥ricos + num√©ricos)</li>
<li><strong>Ensemble:</strong> Reduce overfitting mediante bagging</li>
<li><strong>Escalabilidad:</strong> Paralelizable en m√∫ltiples cores</li>
</ul>
<h3 id="fase-6-evaluaci√≥n-y-validaci√≥n">FASE 6: Evaluaci√≥n y Validaci√≥n </h3>
<p><strong>M√©tricas en Test Set:</strong></p>
<pre data-role="codeBlock" data-info="" class="language-text"><code>Accuracy:  100.0%
Precision: 100.0%
Recall:    100.0%
F1-Score:  100.0%
ROC-AUC:   1.0000
</code></pre><p><strong>Matriz de Confusi√≥n:</strong></p>
<pre data-role="codeBlock" data-info="" class="language-text"><code>              Predicho No    Predicho S√≠
Real No           3,923            0
Real S√≠               0        5,776
</code></pre><p><strong>Top 5 Features M√°s Importantes:</strong></p>
<ol>
<li>Type Match (tipo_coincide)</li>
<li>CWE Match (cwe_coincide)</li>
<li>TF-IDF features de descripciones</li>
<li>Severity similarity</li>
<li>Tool compatibility</li>
</ol>
<h3 id="fase-7-persistencia-del-modelo">FASE 7: Persistencia del Modelo </h3>
<p><strong>Archivos Generados:</strong></p>
<ol>
<li>
<p><strong>rf_correlator_v1.pkl</strong> (70 MB)</p>
<ul>
<li>Random Forest classifier</li>
<li>TF-IDF vectorizer</li>
<li>Label encoders</li>
<li>Metadata del modelo</li>
</ul>
</li>
<li>
<p><strong>metadata.json</strong></p>
</li>
</ol>
<pre data-role="codeBlock" data-info="json" class="language-json json"><code><span class="token punctuation">{</span>
  <span class="token property">"validation"</span><span class="token operator">:</span> <span class="token punctuation">{</span>
    <span class="token property">"accuracy"</span><span class="token operator">:</span> <span class="token number">1.0</span><span class="token punctuation">,</span>
    <span class="token property">"precision"</span><span class="token operator">:</span> <span class="token number">1.0</span><span class="token punctuation">,</span>
    <span class="token property">"recall"</span><span class="token operator">:</span> <span class="token number">1.0</span><span class="token punctuation">,</span>
    <span class="token property">"f1_score"</span><span class="token operator">:</span> <span class="token number">1.0</span><span class="token punctuation">,</span>
    <span class="token property">"roc_auc"</span><span class="token operator">:</span> <span class="token number">1.0</span>
  <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token property">"test"</span><span class="token operator">:</span> <span class="token punctuation">{</span>
    <span class="token property">"accuracy"</span><span class="token operator">:</span> <span class="token number">1.0</span><span class="token punctuation">,</span>
    <span class="token property">"precision"</span><span class="token operator">:</span> <span class="token number">1.0</span><span class="token punctuation">,</span>
    <span class="token property">"recall"</span><span class="token operator">:</span> <span class="token number">1.0</span><span class="token punctuation">,</span>
    <span class="token property">"f1_score"</span><span class="token operator">:</span> <span class="token number">1.0</span><span class="token punctuation">,</span>
    <span class="token property">"roc_auc"</span><span class="token operator">:</span> <span class="token number">1.0</span>
  <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token property">"training_info"</span><span class="token operator">:</span> <span class="token punctuation">{</span>
    <span class="token property">"n_train_samples"</span><span class="token operator">:</span> <span class="token number">77586</span><span class="token punctuation">,</span>
    <span class="token property">"n_val_samples"</span><span class="token operator">:</span> <span class="token number">9698</span><span class="token punctuation">,</span>
    <span class="token property">"n_test_samples"</span><span class="token operator">:</span> <span class="token number">9699</span><span class="token punctuation">,</span>
    <span class="token property">"n_features"</span><span class="token operator">:</span> <span class="token number">517</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><hr>
<h2 id="4-diagrama-de-secuencia-del-entrenamiento">4. Diagrama de Secuencia del Entrenamiento </h2>
<div class="mermaid">sequenceDiagram
    participant User as üë§ Usuario
    participant Script as üêç train_ml_model.py
    participant Processor as üìä CorrelationMLTrainer
    participant FS as üíæ FileSystem
    participant SKLearn as ü§ñ scikit-learn
    
    User-&gt;&gt;Script: python backend/train_ml_model.py
    activate Script
    
    Script-&gt;&gt;Processor: __init__()
    activate Processor
    Processor--&gt;&gt;Script: trainer instance
    
    Script-&gt;&gt;Processor: load_datasets()
    Processor-&gt;&gt;FS: read training_set.csv
    FS--&gt;&gt;Processor: 77,586 rows
    Processor-&gt;&gt;FS: read validation_set.csv
    FS--&gt;&gt;Processor: 9,698 rows
    Processor-&gt;&gt;FS: read test_set.csv
    FS--&gt;&gt;Processor: 9,699 rows
    Processor--&gt;&gt;Script: datasets loaded
    
    Script-&gt;&gt;Processor: train_model()
    
    Note over Processor: FASE: Feature Engineering
    Processor-&gt;&gt;Processor: engineer_features(train_df, fit=True)
    Processor-&gt;&gt;SKLearn: TfidfVectorizer.fit_transform()
    SKLearn--&gt;&gt;Processor: TF-IDF matrix (500 features)
    Processor-&gt;&gt;SKLearn: LabelEncoder.fit_transform()
    SKLearn--&gt;&gt;Processor: encoded categories
    Processor-&gt;&gt;Processor: compute numeric features
    Processor-&gt;&gt;Processor: concatenate all features
    Processor--&gt;&gt;Processor: X_train (77,586 √ó 517)
    
    Processor-&gt;&gt;Processor: engineer_features(val_df, fit=False)
    Processor--&gt;&gt;Processor: X_val (9,698 √ó 517)
    
    Processor-&gt;&gt;Processor: engineer_features(test_df, fit=False)
    Processor--&gt;&gt;Processor: X_test (9,699 √ó 517)
    
    Note over Processor,SKLearn: FASE: Entrenamiento
    Processor-&gt;&gt;SKLearn: RandomForestClassifier()
    SKLearn--&gt;&gt;Processor: rf_classifier instance
    
    Processor-&gt;&gt;SKLearn: fit(X_train, y_train)
    Note right of SKLearn: Construyendo 200 √°rboles&lt;br/&gt;en paralelo (n_jobs=-1)
    SKLearn--&gt;&gt;Processor: model trained
    
    Script-&gt;&gt;Processor: evaluate_model()
    
    Note over Processor,SKLearn: FASE: Evaluaci√≥n
    Processor-&gt;&gt;SKLearn: predict(X_val)
    SKLearn--&gt;&gt;Processor: y_val_pred
    Processor-&gt;&gt;SKLearn: predict_proba(X_val)
    SKLearn--&gt;&gt;Processor: y_val_proba
    
    Processor-&gt;&gt;SKLearn: predict(X_test)
    SKLearn--&gt;&gt;Processor: y_test_pred
    Processor-&gt;&gt;SKLearn: predict_proba(X_test)
    SKLearn--&gt;&gt;Processor: y_test_proba
    
    Processor-&gt;&gt;SKLearn: accuracy_score()
    SKLearn--&gt;&gt;Processor: 1.0
    Processor-&gt;&gt;SKLearn: precision_recall_fscore_support()
    SKLearn--&gt;&gt;Processor: P=1.0, R=1.0, F1=1.0
    Processor-&gt;&gt;SKLearn: roc_auc_score()
    SKLearn--&gt;&gt;Processor: AUC=1.0
    Processor-&gt;&gt;SKLearn: confusion_matrix()
    SKLearn--&gt;&gt;Processor: [[3923, 0], [0, 5776]]
    
    Processor--&gt;&gt;Script: metrics computed
    
    Script-&gt;&gt;Processor: save_model()
    
    Note over Processor,FS: FASE: Persistencia
    Processor-&gt;&gt;Processor: package_model()
    Processor-&gt;&gt;FS: joblib.dump(model, rf_correlator_v1.pkl)
    FS--&gt;&gt;Processor: saved (70 MB)
    Processor-&gt;&gt;FS: json.dump(metadata, metadata.json)
    FS--&gt;&gt;Processor: saved
    
    Processor--&gt;&gt;Script: model saved
    deactivate Processor
    
    Script--&gt;&gt;User: ‚úÖ ENTRENAMIENTO COMPLETADO&lt;br/&gt;F1-Score: 100%
    deactivate Script
</div><hr>
<h2 id="5-diagrama-de-clases-del-pipeline-ml">5. Diagrama de Clases del Pipeline ML </h2>
<div class="mermaid">classDiagram
    class CorrelationMLTrainer {
        -Path data_dir
        -Path model_dir
        -RandomForestClassifier rf_classifier
        -TfidfVectorizer tfidf_vectorizer
        -Dict label_encoders
        -ndarray X_train
        -ndarray y_train
        -ndarray X_val
        -ndarray y_val
        -ndarray X_test
        -ndarray y_test
        -Dict training_metrics
        
        +__init__(data_dir, model_dir)
        +load_datasets() void
        +engineer_features(df, fit) ndarray
        +train_model() void
        +evaluate_model() void
        +save_model() void
        +run_full_pipeline() void
    }
    
    class RandomForestClassifier {
        -int n_estimators
        -int max_depth
        -int min_samples_split
        -int min_samples_leaf
        -str max_features
        -str class_weight
        -int random_state
        -int n_jobs
        
        +fit(X, y) self
        +predict(X) ndarray
        +predict_proba(X) ndarray
        +feature_importances_ ndarray
    }
    
    class TfidfVectorizer {
        -int max_features
        -str stop_words
        -tuple ngram_range
        -int min_df
        -Dict vocabulary_
        
        +fit(documents) self
        +transform(documents) sparse_matrix
        +fit_transform(documents) sparse_matrix
    }
    
    class LabelEncoder {
        -ndarray classes_
        
        +fit(y) self
        +transform(y) ndarray
        +fit_transform(y) ndarray
        +inverse_transform(y) ndarray
    }
    
    class ModelPackage {
        +RandomForestClassifier classifier
        +TfidfVectorizer tfidf_vectorizer
        +Dict~str,LabelEncoder~ label_encoders
        +int feature_count
        +str version
        +str trained_at
    }
    
    class Metadata {
        +Dict validation
        +Dict test
        +Dict confusion_matrix
        +Dict training_info
    }
    
    CorrelationMLTrainer --&gt; RandomForestClassifier : uses
    CorrelationMLTrainer --&gt; TfidfVectorizer : uses
    CorrelationMLTrainer --&gt; LabelEncoder : uses
    CorrelationMLTrainer ..&gt; ModelPackage : creates
    CorrelationMLTrainer ..&gt; Metadata : generates
    RandomForestClassifier --|&gt; BaseEstimator : inherits
    TfidfVectorizer --|&gt; BaseEstimator : inherits
    LabelEncoder --|&gt; BaseEstimator : inherits
</div><hr>
<h2 id="6-m√©tricas-de-evaluaci√≥n-del-modelo">6. M√©tricas de Evaluaci√≥n del Modelo </h2>
<h3 id="tabla-de-m√©tricas">Tabla de M√©tricas </h3>
<table>
<thead>
<tr>
<th>M√©trica</th>
<th>Validation Set</th>
<th>Test Set</th>
<th>Interpretaci√≥n</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Accuracy</strong></td>
<td>100.0%</td>
<td>100.0%</td>
<td>Proporci√≥n de predicciones correctas</td>
</tr>
<tr>
<td><strong>Precision</strong></td>
<td>100.0%</td>
<td>100.0%</td>
<td>De las predichas como correlacionadas, cu√°ntas lo son realmente</td>
</tr>
<tr>
<td><strong>Recall</strong></td>
<td>100.0%</td>
<td>100.0%</td>
<td>De las realmente correlacionadas, cu√°ntas se detectan</td>
</tr>
<tr>
<td><strong>F1-Score</strong></td>
<td>100.0%</td>
<td>100.0%</td>
<td>Media arm√≥nica de Precision y Recall</td>
</tr>
<tr>
<td><strong>ROC-AUC</strong></td>
<td>1.0000</td>
<td>1.0000</td>
<td>√Årea bajo la curva ROC (capacidad discriminativa)</td>
</tr>
</tbody>
</table>
<h3 id="matriz-de-confusi√≥n-test-set">Matriz de Confusi√≥n (Test Set) </h3>
<table>
<thead>
<tr>
<th></th>
<th>Predicho: No Correlacionadas</th>
<th>Predicho: Correlacionadas</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Real: No Correlacionadas</strong></td>
<td><strong>TN = 3,923</strong></td>
<td>FP = 0</td>
</tr>
<tr>
<td><strong>Real: Correlacionadas</strong></td>
<td>FN = 0</td>
<td><strong>TP = 5,776</strong></td>
</tr>
</tbody>
</table>
<p><strong>Interpretaci√≥n:</strong></p>
<ul>
<li><strong>True Negatives (TN):</strong> 3,923 casos correctamente identificados como no correlacionados</li>
<li><strong>True Positives (TP):</strong> 5,776 casos correctamente identificados como correlacionados</li>
<li><strong>False Positives (FP):</strong> 0 casos (no hay falsos positivos)</li>
<li><strong>False Negatives (FN):</strong> 0 casos (no hay falsos negativos)</li>
</ul>
<h3 id="distribuci√≥n-de-clases">Distribuci√≥n de Clases </h3>
<pre data-role="codeBlock" data-info="" class="language-text"><code>Training Set (77,586 muestras):
  ‚îú‚îÄ Correlacionadas:     46,686 (60.2%)
  ‚îî‚îÄ No Correlacionadas:  30,900 (39.8%)

Validation Set (9,698 muestras):
  ‚îú‚îÄ Correlacionadas:     5,843 (60.2%)
  ‚îî‚îÄ No Correlacionadas:  3,855 (39.8%)

Test Set (9,699 muestras):
  ‚îú‚îÄ Correlacionadas:     5,776 (59.5%)
  ‚îî‚îÄ No Correlacionadas:  3,923 (40.5%)
</code></pre><hr>
<h2 id="7-consideraciones-para-tesis">7. Consideraciones para Tesis </h2>
<h3 id="validez-acad√©mica-del-modelo">Validez Acad√©mica del Modelo </h3>
<p><strong>Fortalezas:</strong></p>
<ol>
<li><strong>Dataset Robusto:</strong> 318,956 CVEs de fuente oficial (NVD)</li>
<li><strong>Muestra Grande:</strong> 96,983 registros de correlaci√≥n</li>
<li><strong>Features Diversas:</strong> 517 caracter√≠sticas (texto + categ√≥ricas + num√©ricas)</li>
<li><strong>Split Estratificado:</strong> 80/10/10 con balance de clases</li>
<li><strong>Reproducibilidad:</strong> <code>random_state=42</code> en todos los procesos</li>
</ol>
<p><strong>Limitaciones a Mencionar:</strong></p>
<ol>
<li><strong>Datos Sint√©ticos:</strong> Las correlaciones fueron generadas con reglas determin√≠sticas, no provienen de ejecuciones reales de herramientas SAST/DAST</li>
<li><strong>M√©tricas Perfectas:</strong> 100% accuracy sugiere que el problema es demasiado simple con los datos sint√©ticos</li>
<li><strong>Sesgo de Generaci√≥n:</strong> El modelo aprende los mismos patrones con los que se generaron los datos</li>
</ol>
<p><strong>Recomendaci√≥n para la Tesis:</strong></p>
<ul>
<li>Presentar este modelo como <strong>prueba de concepto (PoC)</strong> del pipeline</li>
<li>Mencionar que en producci√≥n se requerir√≠a:
<ul>
<li>Ejecutar Bandit/Semgrep/ZAP sobre c√≥digo vulnerable real</li>
<li>Etiquetar manualmente las correlaciones verdaderas</li>
<li>Re-entrenar con datos reales</li>
<li>Esperar m√©tricas m√°s realistas: F1 ~ 85-92%</li>
</ul>
</li>
</ul>
<h3 id="citas-recomendadas">Citas Recomendadas </h3>
<pre data-role="codeBlock" data-info="bibtex" class="language-bibtex bibtex"><code>@misc{nvd2025,
  author = {{National Institute of Standards and Technology}},
  title = {{National Vulnerability Database}},
  year = {2025},
  url = {https://nvd.nist.gov/},
  note = {Accessed: 2025-11-21. Total CVEs procesados: 318,956}
}

@article{breiman2001random,
  title={Random forests},
  author={Breiman, Leo},
  journal={Machine learning},
  volume={45},
  number={1},
  pages={5--32},
  year={2001},
  publisher={Springer}
}

@article{pedregosa2011scikit,
  title={Scikit-learn: Machine learning in Python},
  author={Pedregosa, Fabian and others},
  journal={Journal of machine learning research},
  volume={12},
  pages={2825--2830},
  year={2011}
}
</code></pre><hr>
<h2 id="8-ejemplo-de-uso-del-modelo-entrenado">8. Ejemplo de Uso del Modelo Entrenado </h2>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-import">import</span> joblib
<span class="token keyword keyword-import">import</span> pandas <span class="token keyword keyword-as">as</span> pd
<span class="token keyword keyword-import">import</span> numpy <span class="token keyword keyword-as">as</span> np

<span class="token comment"># Cargar modelo entrenado</span>
model_package <span class="token operator">=</span> joblib<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'data/models/rf_correlator_v1.pkl'</span><span class="token punctuation">)</span>

rf_classifier <span class="token operator">=</span> model_package<span class="token punctuation">[</span><span class="token string">'classifier'</span><span class="token punctuation">]</span>
tfidf_vectorizer <span class="token operator">=</span> model_package<span class="token punctuation">[</span><span class="token string">'tfidf_vectorizer'</span><span class="token punctuation">]</span>
label_encoders <span class="token operator">=</span> model_package<span class="token punctuation">[</span><span class="token string">'label_encoders'</span><span class="token punctuation">]</span>

<span class="token comment"># Datos de ejemplo (hallazgos SAST y DAST)</span>
new_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">{</span>
    <span class="token string">'sast_description'</span><span class="token punctuation">:</span> <span class="token string">'SQL query uses string concatenation vulnerable to injection'</span><span class="token punctuation">,</span>
    <span class="token string">'dast_description'</span><span class="token punctuation">:</span> <span class="token string">'SQL error detected in HTTP response'</span><span class="token punctuation">,</span>
    <span class="token string">'sast_type'</span><span class="token punctuation">:</span> <span class="token string">'SQL_INJECTION'</span><span class="token punctuation">,</span>
    <span class="token string">'dast_type'</span><span class="token punctuation">:</span> <span class="token string">'SQL_INJECTION'</span><span class="token punctuation">,</span>
    <span class="token string">'sast_severity'</span><span class="token punctuation">:</span> <span class="token string">'HIGH'</span><span class="token punctuation">,</span>
    <span class="token string">'dast_severity'</span><span class="token punctuation">:</span> <span class="token string">'HIGH'</span><span class="token punctuation">,</span>
    <span class="token string">'sast_cwe'</span><span class="token punctuation">:</span> <span class="token string">'CWE-89'</span><span class="token punctuation">,</span>
    <span class="token string">'dast_cwe'</span><span class="token punctuation">:</span> <span class="token string">'CWE-89'</span><span class="token punctuation">,</span>
    <span class="token string">'sast_tool'</span><span class="token punctuation">:</span> <span class="token string">'bandit'</span><span class="token punctuation">,</span>
    <span class="token string">'dast_tool'</span><span class="token punctuation">:</span> <span class="token string">'zap'</span><span class="token punctuation">,</span>
    <span class="token string">'sast_file'</span><span class="token punctuation">:</span> <span class="token string">'src/api/auth.py'</span><span class="token punctuation">,</span>
    <span class="token string">'dast_endpoint'</span><span class="token punctuation">:</span> <span class="token string">'/api/login'</span><span class="token punctuation">,</span>
    <span class="token string">'sast_line'</span><span class="token punctuation">:</span> <span class="token number">45</span>
<span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># Feature engineering (mismo proceso que en entrenamiento)</span>
<span class="token comment"># ... (c√≥digo omitido por brevedad)</span>

<span class="token comment"># Predicci√≥n</span>
prediction <span class="token operator">=</span> rf_classifier<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_new<span class="token punctuation">)</span>
probability <span class="token operator">=</span> rf_classifier<span class="token punctuation">.</span>predict_proba<span class="token punctuation">(</span>X_new<span class="token punctuation">)</span>

<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"¬øEst√°n correlacionadas? </span><span class="token interpolation"><span class="token punctuation">{</span>prediction<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Confianza: </span><span class="token interpolation"><span class="token punctuation">{</span>probability<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token format-spec">.2%</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
<span class="token comment"># Output: ¬øEst√°n correlacionadas? 1</span>
<span class="token comment">#         Confianza: 98.5%</span>
</code></pre><hr>
<p><strong>Fin del Documento de Pipeline ML</strong></p>

      </div>
      
      
    
    
    <script type="module">
// TODO: If ZenUML gets integrated into mermaid in the future,
//      we can remove the following lines.


var MERMAID_CONFIG = ({"startOnLoad":false});
if (typeof MERMAID_CONFIG !== 'undefined') {
  MERMAID_CONFIG.startOnLoad = false
  MERMAID_CONFIG.cloneCssStyles = false
  MERMAID_CONFIG.theme = "default"
}

mermaid.initialize(MERMAID_CONFIG || {})
if (typeof(window['Reveal']) !== 'undefined') {
  function mermaidRevealHelper(event) {
    var currentSlide = event.currentSlide
    var diagrams = currentSlide.querySelectorAll('.mermaid')
    for (var i = 0; i < diagrams.length; i++) {
      var diagram = diagrams[i]
      if (!diagram.hasAttribute('data-processed')) {
        mermaid.init(null, diagram, ()=> {
          Reveal.slide(event.indexh, event.indexv)
        })
      }
    }
  }
  Reveal.addEventListener('slidetransitionend', mermaidRevealHelper)
  Reveal.addEventListener('ready', mermaidRevealHelper)
  await mermaid.run({
    nodes: document.querySelectorAll('.mermaid')
  })
} else {
  await mermaid.run({
    nodes: document.querySelectorAll('.mermaid')
  })
}
</script>
    
    
    
  
    </body></html>